{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0b8d4335",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Karthik Garimella\\Desktop\\Classes\\CS4811 Artificial Intelligence\\Wordle Program\\words_alpha.txt\") as f:\n",
    "    lines = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3f07021d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aah',\n",
       " 'aahed',\n",
       " 'aahing',\n",
       " 'aahs',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aaliis',\n",
       " 'aals',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardvarks',\n",
       " 'aardwolf',\n",
       " 'aardwolves',\n",
       " 'aargh',\n",
       " 'aaron',\n",
       " 'aaronic',\n",
       " 'aaronical',\n",
       " 'aaronite',\n",
       " 'aaronitic',\n",
       " 'aarrgh',\n",
       " 'aarrghh',\n",
       " 'aaru',\n",
       " 'aas',\n",
       " 'aasvogel',\n",
       " 'aasvogels',\n",
       " 'ab',\n",
       " 'aba',\n",
       " 'ababdeh',\n",
       " 'ababua',\n",
       " 'abac',\n",
       " 'abaca',\n",
       " 'abacay',\n",
       " 'abacas',\n",
       " 'abacate',\n",
       " 'abacaxi',\n",
       " 'abaci',\n",
       " 'abacinate',\n",
       " 'abacination',\n",
       " 'abacisci',\n",
       " 'abaciscus',\n",
       " 'abacist',\n",
       " 'aback',\n",
       " 'abacli',\n",
       " 'abacot',\n",
       " 'abacterial',\n",
       " 'abactinal',\n",
       " 'abactinally',\n",
       " 'abaction',\n",
       " 'abactor',\n",
       " 'abaculi',\n",
       " 'abaculus',\n",
       " 'abacus',\n",
       " 'abacuses',\n",
       " 'abada',\n",
       " 'abaddon',\n",
       " 'abadejo',\n",
       " 'abadengo',\n",
       " 'abadia',\n",
       " 'abadite',\n",
       " 'abaff',\n",
       " 'abaft',\n",
       " 'abay',\n",
       " 'abayah',\n",
       " 'abaisance',\n",
       " 'abaised',\n",
       " 'abaiser',\n",
       " 'abaisse',\n",
       " 'abaissed',\n",
       " 'abaka',\n",
       " 'abakas',\n",
       " 'abalation',\n",
       " 'abalienate',\n",
       " 'abalienated',\n",
       " 'abalienating',\n",
       " 'abalienation',\n",
       " 'abalone',\n",
       " 'abalones',\n",
       " 'abama',\n",
       " 'abamp',\n",
       " 'abampere',\n",
       " 'abamperes',\n",
       " 'abamps',\n",
       " 'aband',\n",
       " 'abandon',\n",
       " 'abandonable',\n",
       " 'abandoned',\n",
       " 'abandonedly',\n",
       " 'abandonee',\n",
       " 'abandoner',\n",
       " 'abandoners',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abandonments',\n",
       " 'abandons',\n",
       " 'abandum',\n",
       " 'abanet',\n",
       " 'abanga',\n",
       " 'abanic',\n",
       " 'abannition',\n",
       " 'abantes',\n",
       " 'abapical',\n",
       " 'abaptiston',\n",
       " 'abaptistum',\n",
       " 'abarambo',\n",
       " 'abaris',\n",
       " 'abarthrosis',\n",
       " 'abarticular',\n",
       " 'abarticulation',\n",
       " 'abas',\n",
       " 'abase',\n",
       " 'abased',\n",
       " 'abasedly',\n",
       " 'abasedness',\n",
       " 'abasement',\n",
       " 'abasements',\n",
       " 'abaser',\n",
       " 'abasers',\n",
       " 'abases',\n",
       " 'abasgi',\n",
       " 'abash',\n",
       " 'abashed',\n",
       " 'abashedly',\n",
       " 'abashedness',\n",
       " 'abashes',\n",
       " 'abashing',\n",
       " 'abashless',\n",
       " 'abashlessly',\n",
       " 'abashment',\n",
       " 'abashments',\n",
       " 'abasia',\n",
       " 'abasias',\n",
       " 'abasic',\n",
       " 'abasing',\n",
       " 'abasio',\n",
       " 'abask',\n",
       " 'abassi',\n",
       " 'abassin',\n",
       " 'abastard',\n",
       " 'abastardize',\n",
       " 'abastral',\n",
       " 'abatable',\n",
       " 'abatage',\n",
       " 'abate',\n",
       " 'abated',\n",
       " 'abatement',\n",
       " 'abatements',\n",
       " 'abater',\n",
       " 'abaters',\n",
       " 'abates',\n",
       " 'abatic',\n",
       " 'abating',\n",
       " 'abatis',\n",
       " 'abatised',\n",
       " 'abatises',\n",
       " 'abatjour',\n",
       " 'abatjours',\n",
       " 'abaton',\n",
       " 'abator',\n",
       " 'abators',\n",
       " 'abattage',\n",
       " 'abattis',\n",
       " 'abattised',\n",
       " 'abattises',\n",
       " 'abattoir',\n",
       " 'abattoirs',\n",
       " 'abattu',\n",
       " 'abattue',\n",
       " 'abatua',\n",
       " 'abature',\n",
       " 'abaue',\n",
       " 'abave',\n",
       " 'abaxial',\n",
       " 'abaxile',\n",
       " 'abaze',\n",
       " 'abb',\n",
       " 'abba',\n",
       " 'abbacy',\n",
       " 'abbacies',\n",
       " 'abbacomes',\n",
       " 'abbadide',\n",
       " 'abbaye',\n",
       " 'abbandono',\n",
       " 'abbas',\n",
       " 'abbasi',\n",
       " 'abbasid',\n",
       " 'abbassi',\n",
       " 'abbasside',\n",
       " 'abbate',\n",
       " 'abbatial',\n",
       " 'abbatical',\n",
       " 'abbatie',\n",
       " 'abbe',\n",
       " 'abbey',\n",
       " 'abbeys',\n",
       " 'abbeystead',\n",
       " 'abbeystede',\n",
       " 'abbes',\n",
       " 'abbess',\n",
       " 'abbesses',\n",
       " 'abbest',\n",
       " 'abbevillian',\n",
       " 'abby',\n",
       " 'abbie',\n",
       " 'abboccato',\n",
       " 'abbogada',\n",
       " 'abbot',\n",
       " 'abbotcy',\n",
       " 'abbotcies',\n",
       " 'abbotnullius',\n",
       " 'abbotric',\n",
       " 'abbots',\n",
       " 'abbotship',\n",
       " 'abbotships',\n",
       " 'abbott',\n",
       " 'abbozzo',\n",
       " 'abbr',\n",
       " 'abbrev',\n",
       " 'abbreviatable',\n",
       " 'abbreviate',\n",
       " 'abbreviated',\n",
       " 'abbreviately',\n",
       " 'abbreviates',\n",
       " 'abbreviating',\n",
       " 'abbreviation',\n",
       " 'abbreviations',\n",
       " 'abbreviator',\n",
       " 'abbreviatory',\n",
       " 'abbreviators',\n",
       " 'abbreviature',\n",
       " 'abbroachment',\n",
       " 'abc',\n",
       " 'abcess',\n",
       " 'abcissa',\n",
       " 'abcoulomb',\n",
       " 'abd',\n",
       " 'abdal',\n",
       " 'abdali',\n",
       " 'abdaria',\n",
       " 'abdat',\n",
       " 'abderian',\n",
       " 'abderite',\n",
       " 'abdest',\n",
       " 'abdicable',\n",
       " 'abdicant',\n",
       " 'abdicate',\n",
       " 'abdicated',\n",
       " 'abdicates',\n",
       " 'abdicating',\n",
       " 'abdication',\n",
       " 'abdications',\n",
       " 'abdicative',\n",
       " 'abdicator',\n",
       " 'abdiel',\n",
       " 'abditive',\n",
       " 'abditory',\n",
       " 'abdom',\n",
       " 'abdomen',\n",
       " 'abdomens',\n",
       " 'abdomina',\n",
       " 'abdominal',\n",
       " 'abdominales',\n",
       " 'abdominalia',\n",
       " 'abdominalian',\n",
       " 'abdominally',\n",
       " 'abdominals',\n",
       " 'abdominoanterior',\n",
       " 'abdominocardiac',\n",
       " 'abdominocentesis',\n",
       " 'abdominocystic',\n",
       " 'abdominogenital',\n",
       " 'abdominohysterectomy',\n",
       " 'abdominohysterotomy',\n",
       " 'abdominoposterior',\n",
       " 'abdominoscope',\n",
       " 'abdominoscopy',\n",
       " 'abdominothoracic',\n",
       " 'abdominous',\n",
       " 'abdominovaginal',\n",
       " 'abdominovesical',\n",
       " 'abduce',\n",
       " 'abduced',\n",
       " 'abducens',\n",
       " 'abducent',\n",
       " 'abducentes',\n",
       " 'abduces',\n",
       " 'abducing',\n",
       " 'abduct',\n",
       " 'abducted',\n",
       " 'abducting',\n",
       " 'abduction',\n",
       " 'abductions',\n",
       " 'abductor',\n",
       " 'abductores',\n",
       " 'abductors',\n",
       " 'abducts',\n",
       " 'abe',\n",
       " 'abeam',\n",
       " 'abear',\n",
       " 'abearance',\n",
       " 'abecedaire',\n",
       " 'abecedary',\n",
       " 'abecedaria',\n",
       " 'abecedarian',\n",
       " 'abecedarians',\n",
       " 'abecedaries',\n",
       " 'abecedarium',\n",
       " 'abecedarius',\n",
       " 'abed',\n",
       " 'abede',\n",
       " 'abedge',\n",
       " 'abegge',\n",
       " 'abey',\n",
       " 'abeyance',\n",
       " 'abeyances',\n",
       " 'abeyancy',\n",
       " 'abeyancies',\n",
       " 'abeyant',\n",
       " 'abeigh',\n",
       " 'abel',\n",
       " 'abele',\n",
       " 'abeles',\n",
       " 'abelia',\n",
       " 'abelian',\n",
       " 'abelicea',\n",
       " 'abelite',\n",
       " 'abelmoschus',\n",
       " 'abelmosk',\n",
       " 'abelmosks',\n",
       " 'abelmusk',\n",
       " 'abelonian',\n",
       " 'abeltree',\n",
       " 'abencerrages',\n",
       " 'abend',\n",
       " 'abends',\n",
       " 'abenteric',\n",
       " 'abepithymia',\n",
       " 'aberdavine',\n",
       " 'aberdeen',\n",
       " 'aberdevine',\n",
       " 'aberdonian',\n",
       " 'aberduvine',\n",
       " 'aberia',\n",
       " 'abernethy',\n",
       " 'aberr',\n",
       " 'aberrance',\n",
       " 'aberrancy',\n",
       " 'aberrancies',\n",
       " 'aberrant',\n",
       " 'aberrantly',\n",
       " 'aberrants',\n",
       " 'aberrate',\n",
       " 'aberrated',\n",
       " 'aberrating',\n",
       " 'aberration',\n",
       " 'aberrational',\n",
       " 'aberrations',\n",
       " 'aberrative',\n",
       " 'aberrator',\n",
       " 'aberrometer',\n",
       " 'aberroscope',\n",
       " 'aberuncate',\n",
       " 'aberuncator',\n",
       " 'abesse',\n",
       " 'abessive',\n",
       " 'abet',\n",
       " 'abetment',\n",
       " 'abetments',\n",
       " 'abets',\n",
       " 'abettal',\n",
       " 'abettals',\n",
       " 'abetted',\n",
       " 'abetter',\n",
       " 'abetters',\n",
       " 'abetting',\n",
       " 'abettor',\n",
       " 'abettors',\n",
       " 'abevacuation',\n",
       " 'abfarad',\n",
       " 'abfarads',\n",
       " 'abhenry',\n",
       " 'abhenries',\n",
       " 'abhenrys',\n",
       " 'abhinaya',\n",
       " 'abhiseka',\n",
       " 'abhominable',\n",
       " 'abhor',\n",
       " 'abhorred',\n",
       " 'abhorrence',\n",
       " 'abhorrences',\n",
       " 'abhorrency',\n",
       " 'abhorrent',\n",
       " 'abhorrently',\n",
       " 'abhorrer',\n",
       " 'abhorrers',\n",
       " 'abhorrible',\n",
       " 'abhorring',\n",
       " 'abhors',\n",
       " 'abhorson',\n",
       " 'aby',\n",
       " 'abib',\n",
       " 'abichite',\n",
       " 'abidal',\n",
       " 'abidance',\n",
       " 'abidances',\n",
       " 'abidden',\n",
       " 'abide',\n",
       " 'abided',\n",
       " 'abider',\n",
       " 'abiders',\n",
       " 'abides',\n",
       " 'abidi',\n",
       " 'abiding',\n",
       " 'abidingly',\n",
       " 'abidingness',\n",
       " 'abie',\n",
       " 'abye',\n",
       " 'abiegh',\n",
       " 'abience',\n",
       " 'abient',\n",
       " 'abies',\n",
       " 'abyes',\n",
       " 'abietate',\n",
       " 'abietene',\n",
       " 'abietic',\n",
       " 'abietin',\n",
       " 'abietineae',\n",
       " 'abietineous',\n",
       " 'abietinic',\n",
       " 'abietite',\n",
       " 'abiezer',\n",
       " 'abigail',\n",
       " 'abigails',\n",
       " 'abigailship',\n",
       " 'abigeat',\n",
       " 'abigei',\n",
       " 'abigeus',\n",
       " 'abying',\n",
       " 'abilao',\n",
       " 'abilene',\n",
       " 'abiliment',\n",
       " 'abilitable',\n",
       " 'ability',\n",
       " 'abilities',\n",
       " 'abilla',\n",
       " 'abilo',\n",
       " 'abime',\n",
       " 'abintestate',\n",
       " 'abiogeneses',\n",
       " 'abiogenesis',\n",
       " 'abiogenesist',\n",
       " 'abiogenetic',\n",
       " 'abiogenetical',\n",
       " 'abiogenetically',\n",
       " 'abiogeny',\n",
       " 'abiogenist',\n",
       " 'abiogenous',\n",
       " 'abiology',\n",
       " 'abiological',\n",
       " 'abiologically',\n",
       " 'abioses',\n",
       " 'abiosis',\n",
       " 'abiotic',\n",
       " 'abiotical',\n",
       " 'abiotically',\n",
       " 'abiotrophy',\n",
       " 'abiotrophic',\n",
       " 'abipon',\n",
       " 'abir',\n",
       " 'abirritant',\n",
       " 'abirritate',\n",
       " 'abirritated',\n",
       " 'abirritating',\n",
       " 'abirritation',\n",
       " 'abirritative',\n",
       " 'abys',\n",
       " 'abysm',\n",
       " 'abysmal',\n",
       " 'abysmally',\n",
       " 'abysms',\n",
       " 'abyss',\n",
       " 'abyssa',\n",
       " 'abyssal',\n",
       " 'abysses',\n",
       " 'abyssinia',\n",
       " 'abyssinian',\n",
       " 'abyssinians',\n",
       " 'abyssobenthonic',\n",
       " 'abyssolith',\n",
       " 'abyssopelagic',\n",
       " 'abyssus',\n",
       " 'abiston',\n",
       " 'abit',\n",
       " 'abitibi',\n",
       " 'abiuret',\n",
       " 'abject',\n",
       " 'abjectedness',\n",
       " 'abjection',\n",
       " 'abjections',\n",
       " 'abjective',\n",
       " 'abjectly',\n",
       " 'abjectness',\n",
       " 'abjoint',\n",
       " 'abjudge',\n",
       " 'abjudged',\n",
       " 'abjudging',\n",
       " 'abjudicate',\n",
       " 'abjudicated',\n",
       " 'abjudicating',\n",
       " 'abjudication',\n",
       " 'abjudicator',\n",
       " 'abjugate',\n",
       " 'abjunct',\n",
       " 'abjunction',\n",
       " 'abjunctive',\n",
       " 'abjuration',\n",
       " 'abjurations',\n",
       " 'abjuratory',\n",
       " 'abjure',\n",
       " 'abjured',\n",
       " 'abjurement',\n",
       " 'abjurer',\n",
       " 'abjurers',\n",
       " 'abjures',\n",
       " 'abjuring',\n",
       " 'abkar',\n",
       " 'abkari',\n",
       " 'abkary',\n",
       " 'abkhas',\n",
       " 'abkhasian',\n",
       " 'abl',\n",
       " 'ablach',\n",
       " 'ablactate',\n",
       " 'ablactated',\n",
       " 'ablactating',\n",
       " 'ablactation',\n",
       " 'ablaqueate',\n",
       " 'ablare',\n",
       " 'ablastemic',\n",
       " 'ablastin',\n",
       " 'ablastous',\n",
       " 'ablate',\n",
       " 'ablated',\n",
       " 'ablates',\n",
       " 'ablating',\n",
       " 'ablation',\n",
       " 'ablations',\n",
       " 'ablatitious',\n",
       " 'ablatival',\n",
       " 'ablative',\n",
       " 'ablatively',\n",
       " 'ablatives',\n",
       " 'ablator',\n",
       " 'ablaut',\n",
       " 'ablauts',\n",
       " 'ablaze',\n",
       " 'able',\n",
       " 'abled',\n",
       " 'ableeze',\n",
       " 'ablegate',\n",
       " 'ablegates',\n",
       " 'ablegation',\n",
       " 'ablend',\n",
       " 'ableness',\n",
       " 'ablepharia',\n",
       " 'ablepharon',\n",
       " 'ablepharous',\n",
       " 'ablepharus',\n",
       " 'ablepsy',\n",
       " 'ablepsia',\n",
       " 'ableptical',\n",
       " 'ableptically',\n",
       " 'abler',\n",
       " 'ables',\n",
       " 'ablesse',\n",
       " 'ablest',\n",
       " 'ablet',\n",
       " 'ablewhackets',\n",
       " 'ably',\n",
       " 'ablings',\n",
       " 'ablins',\n",
       " 'ablock',\n",
       " 'abloom',\n",
       " 'ablow',\n",
       " 'ablude',\n",
       " 'abluent',\n",
       " 'abluents',\n",
       " 'ablush',\n",
       " 'ablute',\n",
       " 'abluted',\n",
       " 'ablution',\n",
       " 'ablutionary',\n",
       " 'ablutions',\n",
       " 'abluvion',\n",
       " 'abmho',\n",
       " 'abmhos',\n",
       " 'abmodality',\n",
       " 'abmodalities',\n",
       " 'abn',\n",
       " 'abnaki',\n",
       " 'abnegate',\n",
       " 'abnegated',\n",
       " 'abnegates',\n",
       " 'abnegating',\n",
       " 'abnegation',\n",
       " 'abnegations',\n",
       " 'abnegative',\n",
       " 'abnegator',\n",
       " 'abnegators',\n",
       " 'abner',\n",
       " 'abnerval',\n",
       " 'abnet',\n",
       " 'abneural',\n",
       " 'abnormal',\n",
       " 'abnormalcy',\n",
       " 'abnormalcies',\n",
       " 'abnormalise',\n",
       " 'abnormalised',\n",
       " 'abnormalising',\n",
       " 'abnormalism',\n",
       " 'abnormalist',\n",
       " 'abnormality',\n",
       " 'abnormalities',\n",
       " 'abnormalize',\n",
       " 'abnormalized',\n",
       " 'abnormalizing',\n",
       " 'abnormally',\n",
       " 'abnormalness',\n",
       " 'abnormals',\n",
       " 'abnormity',\n",
       " 'abnormities',\n",
       " 'abnormous',\n",
       " 'abnumerable',\n",
       " 'abo',\n",
       " 'aboard',\n",
       " 'aboardage',\n",
       " 'abobra',\n",
       " 'abococket',\n",
       " 'abodah',\n",
       " 'abode',\n",
       " 'aboded',\n",
       " 'abodement',\n",
       " 'abodes',\n",
       " 'abody',\n",
       " 'aboding',\n",
       " 'abogado',\n",
       " 'abogados',\n",
       " 'abohm',\n",
       " 'abohms',\n",
       " 'aboideau',\n",
       " 'aboideaus',\n",
       " 'aboideaux',\n",
       " 'aboil',\n",
       " 'aboiteau',\n",
       " 'aboiteaus',\n",
       " 'aboiteaux',\n",
       " 'abolete',\n",
       " 'abolish',\n",
       " 'abolishable',\n",
       " 'abolished',\n",
       " 'abolisher',\n",
       " 'abolishers',\n",
       " 'abolishes',\n",
       " 'abolishing',\n",
       " 'abolishment',\n",
       " 'abolishments',\n",
       " 'abolition',\n",
       " 'abolitionary',\n",
       " 'abolitionise',\n",
       " 'abolitionised',\n",
       " 'abolitionising',\n",
       " 'abolitionism',\n",
       " 'abolitionist',\n",
       " 'abolitionists',\n",
       " 'abolitionize',\n",
       " 'abolitionized',\n",
       " 'abolitionizing',\n",
       " 'abolla',\n",
       " 'abollae',\n",
       " 'aboma',\n",
       " 'abomas',\n",
       " 'abomasa',\n",
       " 'abomasal',\n",
       " 'abomasi',\n",
       " 'abomasum',\n",
       " 'abomasus',\n",
       " 'abomasusi',\n",
       " 'abominability',\n",
       " 'abominable',\n",
       " 'abominableness',\n",
       " 'abominably',\n",
       " 'abominate',\n",
       " 'abominated',\n",
       " 'abominates',\n",
       " 'abominating',\n",
       " 'abomination',\n",
       " 'abominations',\n",
       " 'abominator',\n",
       " 'abominators',\n",
       " 'abomine',\n",
       " 'abondance',\n",
       " 'abongo',\n",
       " 'abonne',\n",
       " 'abonnement',\n",
       " 'aboon',\n",
       " 'aborad',\n",
       " 'aboral',\n",
       " 'aborally',\n",
       " 'abord',\n",
       " 'aboriginal',\n",
       " 'aboriginality',\n",
       " 'aboriginally',\n",
       " 'aboriginals',\n",
       " 'aboriginary',\n",
       " 'aborigine',\n",
       " 'aborigines',\n",
       " 'aborning',\n",
       " 'aborsement',\n",
       " 'aborsive',\n",
       " 'abort',\n",
       " 'aborted',\n",
       " 'aborter',\n",
       " 'aborters',\n",
       " 'aborticide',\n",
       " 'abortient',\n",
       " 'abortifacient',\n",
       " 'abortin',\n",
       " 'aborting',\n",
       " 'abortion',\n",
       " 'abortional',\n",
       " 'abortionist',\n",
       " 'abortionists',\n",
       " 'abortions',\n",
       " 'abortive',\n",
       " 'abortively',\n",
       " 'abortiveness',\n",
       " 'abortogenic',\n",
       " 'aborts',\n",
       " 'abortus',\n",
       " 'abortuses',\n",
       " 'abos',\n",
       " 'abote',\n",
       " 'abouchement',\n",
       " 'aboudikro',\n",
       " 'abought',\n",
       " 'aboulia',\n",
       " 'aboulias',\n",
       " 'aboulic',\n",
       " 'abound',\n",
       " 'abounded',\n",
       " 'abounder',\n",
       " 'abounding',\n",
       " 'aboundingly',\n",
       " 'abounds',\n",
       " 'about',\n",
       " 'abouts',\n",
       " 'above',\n",
       " 'aboveboard',\n",
       " 'abovedeck',\n",
       " 'aboveground',\n",
       " 'abovementioned',\n",
       " 'aboveproof',\n",
       " 'aboves',\n",
       " 'abovesaid',\n",
       " 'abovestairs',\n",
       " 'abow',\n",
       " 'abox',\n",
       " 'abp',\n",
       " 'abr',\n",
       " 'abracadabra',\n",
       " 'abrachia',\n",
       " 'abrachias',\n",
       " 'abradable',\n",
       " 'abradant',\n",
       " 'abradants',\n",
       " 'abrade',\n",
       " 'abraded',\n",
       " 'abrader',\n",
       " 'abraders',\n",
       " 'abrades',\n",
       " 'abrading',\n",
       " 'abraham',\n",
       " 'abrahamic',\n",
       " 'abrahamidae',\n",
       " 'abrahamite',\n",
       " 'abrahamitic',\n",
       " 'abray',\n",
       " 'abraid',\n",
       " 'abram',\n",
       " 'abramis',\n",
       " 'abranchial',\n",
       " 'abranchialism',\n",
       " 'abranchian',\n",
       " 'abranchiata',\n",
       " 'abranchiate',\n",
       " 'abranchious',\n",
       " 'abrasax',\n",
       " 'abrase',\n",
       " 'abrased',\n",
       " 'abraser',\n",
       " 'abrash',\n",
       " 'abrasing',\n",
       " 'abrasiometer',\n",
       " 'abrasion',\n",
       " 'abrasions',\n",
       " 'abrasive',\n",
       " 'abrasively',\n",
       " 'abrasiveness',\n",
       " 'abrasives',\n",
       " 'abrastol',\n",
       " 'abraum',\n",
       " 'abraxas',\n",
       " 'abrazite',\n",
       " 'abrazitic',\n",
       " 'abrazo',\n",
       " 'abrazos',\n",
       " 'abreact',\n",
       " 'abreacted',\n",
       " 'abreacting',\n",
       " 'abreaction',\n",
       " 'abreactions',\n",
       " 'abreacts',\n",
       " 'abreast',\n",
       " 'abreed',\n",
       " 'abrege',\n",
       " 'abreid',\n",
       " 'abrenounce',\n",
       " 'abrenunciate',\n",
       " 'abrenunciation',\n",
       " 'abreption',\n",
       " 'abret',\n",
       " 'abreuvoir',\n",
       " 'abri',\n",
       " 'abrico',\n",
       " 'abricock',\n",
       " 'abricot',\n",
       " 'abridgable',\n",
       " 'abridge',\n",
       " 'abridgeable',\n",
       " 'abridged',\n",
       " 'abridgedly',\n",
       " 'abridgement',\n",
       " 'abridgements',\n",
       " 'abridger',\n",
       " 'abridgers',\n",
       " 'abridges',\n",
       " 'abridging',\n",
       " 'abridgment',\n",
       " 'abridgments',\n",
       " 'abrim',\n",
       " 'abrin',\n",
       " 'abrine',\n",
       " 'abris',\n",
       " 'abristle',\n",
       " 'abroach',\n",
       " 'abroad',\n",
       " 'abrocoma',\n",
       " 'abrocome',\n",
       " 'abrogable',\n",
       " 'abrogate',\n",
       " 'abrogated',\n",
       " 'abrogates',\n",
       " 'abrogating',\n",
       " 'abrogation',\n",
       " 'abrogations',\n",
       " 'abrogative',\n",
       " 'abrogator',\n",
       " 'abrogators',\n",
       " 'abroma',\n",
       " 'abronia',\n",
       " 'abrood',\n",
       " 'abrook',\n",
       " 'abrosia',\n",
       " 'abrosias',\n",
       " 'abrotanum',\n",
       " 'abrotin',\n",
       " 'abrotine',\n",
       " 'abrupt',\n",
       " 'abruptedly',\n",
       " 'abrupter',\n",
       " 'abruptest',\n",
       " 'abruptio',\n",
       " 'abruption',\n",
       " 'abruptiones',\n",
       " 'abruptly',\n",
       " 'abruptness',\n",
       " 'abrus',\n",
       " 'abs',\n",
       " 'absalom',\n",
       " 'absampere',\n",
       " 'absaroka',\n",
       " 'absarokite',\n",
       " 'abscam',\n",
       " 'abscess',\n",
       " 'abscessed',\n",
       " 'abscesses',\n",
       " 'abscessing',\n",
       " 'abscession',\n",
       " 'abscessroot',\n",
       " 'abscind',\n",
       " 'abscise',\n",
       " 'abscised',\n",
       " 'abscises',\n",
       " 'abscising',\n",
       " 'abscisins',\n",
       " 'abscision',\n",
       " 'absciss',\n",
       " 'abscissa',\n",
       " 'abscissae',\n",
       " 'abscissas',\n",
       " 'abscisse',\n",
       " 'abscissin',\n",
       " 'abscission',\n",
       " 'abscissions',\n",
       " 'absconce',\n",
       " 'abscond',\n",
       " 'absconded',\n",
       " 'abscondedly',\n",
       " 'abscondence',\n",
       " 'absconder',\n",
       " 'absconders',\n",
       " 'absconding',\n",
       " 'absconds',\n",
       " 'absconsa',\n",
       " 'abscoulomb',\n",
       " 'abscound',\n",
       " 'absee',\n",
       " 'absey',\n",
       " 'abseil',\n",
       " 'abseiled',\n",
       " 'abseiling',\n",
       " 'abseils',\n",
       " 'absence',\n",
       " 'absences',\n",
       " 'absent',\n",
       " 'absentation',\n",
       " 'absented',\n",
       " 'absentee',\n",
       " 'absenteeism',\n",
       " 'absentees',\n",
       " 'absenteeship',\n",
       " 'absenter',\n",
       " 'absenters',\n",
       " 'absentia',\n",
       " 'absenting',\n",
       " 'absently',\n",
       " 'absentment',\n",
       " 'absentminded',\n",
       " 'absentmindedly',\n",
       " 'absentmindedness',\n",
       " 'absentness',\n",
       " 'absents',\n",
       " 'absfarad',\n",
       " 'abshenry',\n",
       " 'absi',\n",
       " 'absinth',\n",
       " 'absinthe',\n",
       " 'absinthes',\n",
       " 'absinthial',\n",
       " 'absinthian',\n",
       " 'absinthiate',\n",
       " 'absinthiated',\n",
       " 'absinthiating',\n",
       " 'absinthic',\n",
       " 'absinthiin',\n",
       " 'absinthin',\n",
       " 'absinthine',\n",
       " 'absinthism',\n",
       " 'absinthismic',\n",
       " 'absinthium',\n",
       " 'absinthol',\n",
       " 'absinthole',\n",
       " 'absinths',\n",
       " 'absyrtus',\n",
       " 'absis',\n",
       " 'absist',\n",
       " 'absistos',\n",
       " 'absit',\n",
       " 'absmho',\n",
       " 'absohm',\n",
       " 'absoil',\n",
       " 'absolent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absoluteness',\n",
       " 'absoluter',\n",
       " 'absolutes',\n",
       " 'absolutest',\n",
       " 'absolution',\n",
       " 'absolutions',\n",
       " 'absolutism',\n",
       " 'absolutist',\n",
       " 'absolutista',\n",
       " 'absolutistic',\n",
       " 'absolutistically',\n",
       " 'absolutists',\n",
       " 'absolutive',\n",
       " ...]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "76682f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1fcfa02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\anaconda3\\env\\cs4811\\lib\\site-packages (1.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: python-dateutil>=2.7.3 in e:\\anaconda3\\env\\cs4811\\lib\\site-packages (from pandas) (2.8.2)\n",
      "\n",
      "Requirement already satisfied: numpy>=1.15.4 in e:\\anaconda3\\env\\cs4811\\lib\\site-packages (from pandas) (1.19.2)"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b2cd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cd45e27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pytz>=2017.2 in e:\\anaconda3\\env\\cs4811\\lib\\site-packages (from pandas) (2021.3)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8db84614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: six>=1.5 in e:\\anaconda3\\env\\cs4811\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "               words\n",
      "0                  a\n",
      "1                 aa\n",
      "2                aaa\n",
      "3                aah\n",
      "4              aahed\n",
      "...              ...\n",
      "370101  zwinglianist\n",
      "370102       zwitter\n",
      "370103    zwitterion\n",
      "370104  zwitterionic\n",
      "370105              \n",
      "\n",
      "[370106 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(lines, columns =['words'], dtype = str) \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e499726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839bf26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e4b32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59aaf3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba5bdc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8750706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9f459e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordle_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9cb408b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aahed',\n",
       " 'aalii',\n",
       " 'aargh',\n",
       " 'aaron',\n",
       " 'abaca',\n",
       " 'abaci',\n",
       " 'aback',\n",
       " 'abada',\n",
       " 'abaff',\n",
       " 'abaft',\n",
       " 'abaka',\n",
       " 'abama',\n",
       " 'abamp',\n",
       " 'aband',\n",
       " 'abase',\n",
       " 'abash',\n",
       " 'abask',\n",
       " 'abate',\n",
       " 'abaue',\n",
       " 'abave',\n",
       " 'abaze',\n",
       " 'abbas',\n",
       " 'abbey',\n",
       " 'abbes',\n",
       " 'abbie',\n",
       " 'abbot',\n",
       " 'abdal',\n",
       " 'abdat',\n",
       " 'abdom',\n",
       " 'abeam',\n",
       " 'abear',\n",
       " 'abede',\n",
       " 'abele',\n",
       " 'abend',\n",
       " 'aberr',\n",
       " 'abets',\n",
       " 'abhor',\n",
       " 'abide',\n",
       " 'abidi',\n",
       " 'abies',\n",
       " 'abyes',\n",
       " 'abilo',\n",
       " 'abime',\n",
       " 'abysm',\n",
       " 'abyss',\n",
       " 'abkar',\n",
       " 'abled',\n",
       " 'abler',\n",
       " 'ables',\n",
       " 'ablet',\n",
       " 'ablow',\n",
       " 'abmho',\n",
       " 'abner',\n",
       " 'abnet',\n",
       " 'abode',\n",
       " 'abody',\n",
       " 'abohm',\n",
       " 'aboil',\n",
       " 'aboma',\n",
       " 'aboon',\n",
       " 'abord',\n",
       " 'abort',\n",
       " 'abote',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abray',\n",
       " 'abram',\n",
       " 'abret',\n",
       " 'abrim',\n",
       " 'abrin',\n",
       " 'abris',\n",
       " 'abrus',\n",
       " 'absee',\n",
       " 'absey',\n",
       " 'absis',\n",
       " 'absit',\n",
       " 'abstr',\n",
       " 'abuna',\n",
       " 'abune',\n",
       " 'abura',\n",
       " 'abuse',\n",
       " 'abush',\n",
       " 'abuta',\n",
       " 'abuts',\n",
       " 'abuzz',\n",
       " 'abwab',\n",
       " 'acale',\n",
       " 'acana',\n",
       " 'acapu',\n",
       " 'acara',\n",
       " 'acari',\n",
       " 'acast',\n",
       " 'acate',\n",
       " 'accel',\n",
       " 'accoy',\n",
       " 'accra',\n",
       " 'accts',\n",
       " 'accum',\n",
       " 'accur',\n",
       " 'accus',\n",
       " 'acedy',\n",
       " 'acerb',\n",
       " 'aceta',\n",
       " 'achar',\n",
       " 'ached',\n",
       " 'achen',\n",
       " 'acher',\n",
       " 'aches',\n",
       " 'achoo',\n",
       " 'achor',\n",
       " 'acidy',\n",
       " 'acids',\n",
       " 'acier',\n",
       " 'acies',\n",
       " 'acyls',\n",
       " 'acing',\n",
       " 'acini',\n",
       " 'ackee',\n",
       " 'ackey',\n",
       " 'acker',\n",
       " 'aclys',\n",
       " 'acmes',\n",
       " 'acmic',\n",
       " 'acned',\n",
       " 'acnes',\n",
       " 'acock',\n",
       " 'acoin',\n",
       " 'acold',\n",
       " 'acoma',\n",
       " 'acone',\n",
       " 'acool',\n",
       " 'acorn',\n",
       " 'acost',\n",
       " 'acoup',\n",
       " 'acrab',\n",
       " 'acred',\n",
       " 'acres',\n",
       " 'acrid',\n",
       " 'acryl',\n",
       " 'acroa',\n",
       " 'acron',\n",
       " 'acrux',\n",
       " 'acted',\n",
       " 'actin',\n",
       " 'acton',\n",
       " 'actor',\n",
       " 'actos',\n",
       " 'actus',\n",
       " 'acuan',\n",
       " 'acute',\n",
       " 'adage',\n",
       " 'adagy',\n",
       " 'adays',\n",
       " 'adams',\n",
       " 'adapa',\n",
       " 'adapt',\n",
       " 'adati',\n",
       " 'adaty',\n",
       " 'adawe',\n",
       " 'adawn',\n",
       " 'adcon',\n",
       " 'addax',\n",
       " 'addda',\n",
       " 'added',\n",
       " 'adder',\n",
       " 'addie',\n",
       " 'addio',\n",
       " 'addis',\n",
       " 'addle',\n",
       " 'addnl',\n",
       " 'adead',\n",
       " 'adeem',\n",
       " 'adeep',\n",
       " 'adela',\n",
       " 'adeps',\n",
       " 'adept',\n",
       " 'adfix',\n",
       " 'adiel',\n",
       " 'adieu',\n",
       " 'adion',\n",
       " 'adios',\n",
       " 'adyta',\n",
       " 'adits',\n",
       " 'adjag',\n",
       " 'adlai',\n",
       " 'adlay',\n",
       " 'adlet',\n",
       " 'adman',\n",
       " 'admen',\n",
       " 'admin',\n",
       " 'admit',\n",
       " 'admix',\n",
       " 'admov',\n",
       " 'admrx',\n",
       " 'adnex',\n",
       " 'adobe',\n",
       " 'adobo',\n",
       " 'adolf',\n",
       " 'adopt',\n",
       " 'adore',\n",
       " 'adorn',\n",
       " 'adown',\n",
       " 'adoxa',\n",
       " 'adoxy',\n",
       " 'adoze',\n",
       " 'adpao',\n",
       " 'adrad',\n",
       " 'adret',\n",
       " 'adrip',\n",
       " 'adrop',\n",
       " 'adrue',\n",
       " 'adsum',\n",
       " 'adult',\n",
       " 'adunc',\n",
       " 'adure',\n",
       " 'adusk',\n",
       " 'adust',\n",
       " 'adzer',\n",
       " 'adzes',\n",
       " 'aecia',\n",
       " 'aedes',\n",
       " 'aeger',\n",
       " 'aegir',\n",
       " 'aegis',\n",
       " 'aegle',\n",
       " 'aeons',\n",
       " 'aequi',\n",
       " 'aeric',\n",
       " 'aerie',\n",
       " 'aeron',\n",
       " 'aesir',\n",
       " 'aesop',\n",
       " 'aetat',\n",
       " 'aevia',\n",
       " 'aevum',\n",
       " 'aface',\n",
       " 'afara',\n",
       " 'afars',\n",
       " 'afear',\n",
       " 'affix',\n",
       " 'afgod',\n",
       " 'afifi',\n",
       " 'afire',\n",
       " 'aflat',\n",
       " 'afley',\n",
       " 'aflow',\n",
       " 'afoam',\n",
       " 'afoot',\n",
       " 'afore',\n",
       " 'afoul',\n",
       " 'afray',\n",
       " 'afret',\n",
       " 'afric',\n",
       " 'afrit',\n",
       " 'afros',\n",
       " 'after',\n",
       " 'agada',\n",
       " 'agade',\n",
       " 'again',\n",
       " 'agama',\n",
       " 'agami',\n",
       " 'agamy',\n",
       " 'agape',\n",
       " 'agars',\n",
       " 'agasp',\n",
       " 'agast',\n",
       " 'agata',\n",
       " 'agate',\n",
       " 'agaty',\n",
       " 'agave',\n",
       " 'agaze',\n",
       " 'agena',\n",
       " 'agend',\n",
       " 'agene',\n",
       " 'agent',\n",
       " 'agers',\n",
       " 'agete',\n",
       " 'agger',\n",
       " 'aggie',\n",
       " 'aggry',\n",
       " 'aggro',\n",
       " 'aggur',\n",
       " 'aghan',\n",
       " 'aghas',\n",
       " 'agiel',\n",
       " 'agile',\n",
       " 'aging',\n",
       " 'agios',\n",
       " 'agism',\n",
       " 'agist',\n",
       " 'aglee',\n",
       " 'agley',\n",
       " 'aglet',\n",
       " 'aglow',\n",
       " 'agmas',\n",
       " 'agnat',\n",
       " 'agnel',\n",
       " 'agnes',\n",
       " 'agnus',\n",
       " 'agoge',\n",
       " 'agoho',\n",
       " 'agone',\n",
       " 'agony',\n",
       " 'agons',\n",
       " 'agora',\n",
       " 'agrah',\n",
       " 'agral',\n",
       " 'agree',\n",
       " 'agria',\n",
       " 'agric',\n",
       " 'agrin',\n",
       " 'agrom',\n",
       " 'agron',\n",
       " 'agsam',\n",
       " 'aguey',\n",
       " 'agues',\n",
       " 'agura',\n",
       " 'agush',\n",
       " 'agust',\n",
       " 'ahead',\n",
       " 'aheap',\n",
       " 'ahems',\n",
       " 'ahind',\n",
       " 'ahint',\n",
       " 'ahmed',\n",
       " 'ahmet',\n",
       " 'ahold',\n",
       " 'aholt',\n",
       " 'ahong',\n",
       " 'ahsan',\n",
       " 'ahull',\n",
       " 'ahunt',\n",
       " 'ahura',\n",
       " 'ahush',\n",
       " 'ahwal',\n",
       " 'ayahs',\n",
       " 'aided',\n",
       " 'aider',\n",
       " 'aides',\n",
       " 'ayelp',\n",
       " 'ayens',\n",
       " 'aiery',\n",
       " 'aiger',\n",
       " 'aigre',\n",
       " 'ayins',\n",
       " 'ailed',\n",
       " 'aylet',\n",
       " 'ailie',\n",
       " 'aillt',\n",
       " 'ayllu',\n",
       " 'aimak',\n",
       " 'aimed',\n",
       " 'aimee',\n",
       " 'aimer',\n",
       " 'ainee',\n",
       " 'ainoi',\n",
       " 'ainus',\n",
       " 'aioli',\n",
       " 'ayond',\n",
       " 'ayont',\n",
       " 'ayous',\n",
       " 'airan',\n",
       " 'aired',\n",
       " 'airer',\n",
       " 'airns',\n",
       " 'airth',\n",
       " 'airts',\n",
       " 'aisle',\n",
       " 'aitch',\n",
       " 'aitis',\n",
       " 'ayuyu',\n",
       " 'aiver',\n",
       " 'aiwan',\n",
       " 'aizle',\n",
       " 'ajaja',\n",
       " 'ajari',\n",
       " 'ajava',\n",
       " 'ajhar',\n",
       " 'ajiva',\n",
       " 'ajuga',\n",
       " 'akala',\n",
       " 'akali',\n",
       " 'akasa',\n",
       " 'akebi',\n",
       " 'akees',\n",
       " 'akeki',\n",
       " 'akela',\n",
       " 'akene',\n",
       " 'aking',\n",
       " 'akkad',\n",
       " 'aknee',\n",
       " 'aknow',\n",
       " 'akpek',\n",
       " 'akron',\n",
       " 'akule',\n",
       " 'akund',\n",
       " 'alack',\n",
       " 'alada',\n",
       " 'alain',\n",
       " 'alaki',\n",
       " 'alala',\n",
       " 'alamo',\n",
       " 'aland',\n",
       " 'alane',\n",
       " 'alang',\n",
       " 'alani',\n",
       " 'alans',\n",
       " 'alant',\n",
       " 'alapa',\n",
       " 'alary',\n",
       " 'alarm',\n",
       " 'alate',\n",
       " 'alawi',\n",
       " 'alban',\n",
       " 'albas',\n",
       " 'albee',\n",
       " 'albin',\n",
       " 'albyn',\n",
       " 'album',\n",
       " 'albus',\n",
       " 'alcae',\n",
       " 'alces',\n",
       " 'alcid',\n",
       " 'alcor',\n",
       " 'alday',\n",
       " 'aldea',\n",
       " 'alden',\n",
       " 'alder',\n",
       " 'aldim',\n",
       " 'aldol',\n",
       " 'aldus',\n",
       " 'aleak',\n",
       " 'aleck',\n",
       " 'alecs',\n",
       " 'alefs',\n",
       " 'aleft',\n",
       " 'alenu',\n",
       " 'aleph',\n",
       " 'alert',\n",
       " 'aleut',\n",
       " 'alfas',\n",
       " 'alfet',\n",
       " 'alfin',\n",
       " 'alfur',\n",
       " 'algae',\n",
       " 'algal',\n",
       " 'algas',\n",
       " 'algic',\n",
       " 'algid',\n",
       " 'algin',\n",
       " 'algol',\n",
       " 'algor',\n",
       " 'algum',\n",
       " 'alhet',\n",
       " 'alias',\n",
       " 'alibi',\n",
       " 'alice',\n",
       " 'alick',\n",
       " 'alida',\n",
       " 'alids',\n",
       " 'alien',\n",
       " 'aliet',\n",
       " 'alife',\n",
       " 'alifs',\n",
       " 'align',\n",
       " 'aliya',\n",
       " 'alike',\n",
       " 'alima',\n",
       " 'aline',\n",
       " 'alish',\n",
       " 'aliso',\n",
       " 'alisp',\n",
       " 'alist',\n",
       " 'alite',\n",
       " 'ality',\n",
       " 'alive',\n",
       " 'alkes',\n",
       " 'alkyd',\n",
       " 'alkyl',\n",
       " 'alkin',\n",
       " 'allah',\n",
       " 'allay',\n",
       " 'allan',\n",
       " 'alley',\n",
       " 'allen',\n",
       " 'aller',\n",
       " 'allez',\n",
       " 'allie',\n",
       " 'allyl',\n",
       " 'allis',\n",
       " 'allod',\n",
       " 'alloy',\n",
       " 'alloo',\n",
       " 'allot',\n",
       " 'allow',\n",
       " 'almah',\n",
       " 'alman',\n",
       " 'almas',\n",
       " 'almeh',\n",
       " 'almes',\n",
       " 'almon',\n",
       " 'almud',\n",
       " 'almug',\n",
       " 'alnus',\n",
       " 'alody',\n",
       " 'aloed',\n",
       " 'aloes',\n",
       " 'aloft',\n",
       " 'alogy',\n",
       " 'aloha',\n",
       " 'aloid',\n",
       " 'aloin',\n",
       " 'alois',\n",
       " 'aloma',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'aloof',\n",
       " 'alosa',\n",
       " 'alose',\n",
       " 'aloud',\n",
       " 'alout',\n",
       " 'alowe',\n",
       " 'alpax',\n",
       " 'alpen',\n",
       " 'alpha',\n",
       " 'alpid',\n",
       " 'altar',\n",
       " 'alter',\n",
       " 'altho',\n",
       " 'altin',\n",
       " 'altos',\n",
       " 'altun',\n",
       " 'altus',\n",
       " 'aluco',\n",
       " 'alula',\n",
       " 'alums',\n",
       " 'alure',\n",
       " 'aluta',\n",
       " 'alvah',\n",
       " 'alvan',\n",
       " 'alvar',\n",
       " 'alvia',\n",
       " 'alvin',\n",
       " 'alvus',\n",
       " 'alway',\n",
       " 'amaas',\n",
       " 'amadi',\n",
       " 'amaga',\n",
       " 'amahs',\n",
       " 'amain',\n",
       " 'amala',\n",
       " 'amalg',\n",
       " 'amang',\n",
       " 'amani',\n",
       " 'amant',\n",
       " 'amapa',\n",
       " 'amara',\n",
       " 'amass',\n",
       " 'amate',\n",
       " 'amati',\n",
       " 'amaut',\n",
       " 'amaze',\n",
       " 'ambay',\n",
       " 'amban',\n",
       " 'ambar',\n",
       " 'ambas',\n",
       " 'amber',\n",
       " 'ambit',\n",
       " 'amble',\n",
       " 'ambon',\n",
       " 'ambos',\n",
       " 'ambry',\n",
       " 'ameba',\n",
       " 'ameed',\n",
       " 'ameen',\n",
       " 'ameer',\n",
       " 'amelu',\n",
       " 'amend',\n",
       " 'amene',\n",
       " 'amens',\n",
       " 'ament',\n",
       " 'amess',\n",
       " 'amhar',\n",
       " 'amias',\n",
       " 'amice',\n",
       " 'amici',\n",
       " 'amide',\n",
       " 'amido',\n",
       " 'amids',\n",
       " 'amies',\n",
       " 'amiga',\n",
       " 'amigo',\n",
       " 'amylo',\n",
       " 'amyls',\n",
       " 'amine',\n",
       " 'amini',\n",
       " 'amino',\n",
       " 'amins',\n",
       " 'amire',\n",
       " 'amirs',\n",
       " 'amish',\n",
       " 'amiss',\n",
       " 'amita',\n",
       " 'amity',\n",
       " 'amlet',\n",
       " 'amman',\n",
       " 'ammer',\n",
       " 'ammos',\n",
       " 'amnia',\n",
       " 'amnic',\n",
       " 'amoke',\n",
       " 'amoks',\n",
       " 'amole',\n",
       " 'among',\n",
       " 'amora',\n",
       " 'amort',\n",
       " 'amour',\n",
       " 'amove',\n",
       " 'amowt',\n",
       " 'amper',\n",
       " 'amphi',\n",
       " 'ampyx',\n",
       " 'ample',\n",
       " 'amply',\n",
       " 'ampul',\n",
       " 'amrit',\n",
       " 'amsel',\n",
       " 'amuck',\n",
       " 'amula',\n",
       " 'amuse',\n",
       " 'amuze',\n",
       " 'amvis',\n",
       " 'amzel',\n",
       " 'anabo',\n",
       " 'anack',\n",
       " 'anama',\n",
       " 'anana',\n",
       " 'anasa',\n",
       " 'ancha',\n",
       " 'ancle',\n",
       " 'ancon',\n",
       " 'ancor',\n",
       " 'ancre',\n",
       " 'andes',\n",
       " 'andia',\n",
       " 'andor',\n",
       " 'andre',\n",
       " 'anear',\n",
       " 'anele',\n",
       " 'anend',\n",
       " 'anent',\n",
       " 'angas',\n",
       " 'angel',\n",
       " 'anger',\n",
       " 'angia',\n",
       " 'angie',\n",
       " 'angka',\n",
       " 'angle',\n",
       " 'anglo',\n",
       " 'angor',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'angus',\n",
       " 'anhyd',\n",
       " 'aniba',\n",
       " 'anice',\n",
       " 'anigh',\n",
       " 'anile',\n",
       " 'anils',\n",
       " 'anima',\n",
       " 'anime',\n",
       " 'animi',\n",
       " 'animo',\n",
       " 'anion',\n",
       " 'anise',\n",
       " 'anita',\n",
       " 'anjan',\n",
       " 'anjou',\n",
       " 'ankee',\n",
       " 'anker',\n",
       " 'ankhs',\n",
       " 'ankle',\n",
       " 'ankou',\n",
       " 'ankus',\n",
       " 'anlas',\n",
       " 'anlet',\n",
       " 'anlia',\n",
       " 'anmia',\n",
       " 'annal',\n",
       " 'annam',\n",
       " 'annas',\n",
       " 'annat',\n",
       " 'annet',\n",
       " 'annex',\n",
       " 'annie',\n",
       " 'anniv',\n",
       " 'annoy',\n",
       " 'annot',\n",
       " 'annul',\n",
       " 'annum',\n",
       " 'annus',\n",
       " 'anoas',\n",
       " 'anode',\n",
       " 'anoia',\n",
       " 'anoil',\n",
       " 'anole',\n",
       " 'anoli',\n",
       " 'anomy',\n",
       " 'anorn',\n",
       " 'anour',\n",
       " 'anous',\n",
       " 'anova',\n",
       " 'ansae',\n",
       " 'ansar',\n",
       " 'ansel',\n",
       " 'anser',\n",
       " 'antae',\n",
       " 'antal',\n",
       " 'antar',\n",
       " 'antas',\n",
       " 'anted',\n",
       " 'antes',\n",
       " 'antic',\n",
       " 'antiq',\n",
       " 'antis',\n",
       " 'anton',\n",
       " 'antra',\n",
       " 'antre',\n",
       " 'antsy',\n",
       " 'antum',\n",
       " 'anura',\n",
       " 'anury',\n",
       " 'anvil',\n",
       " 'anzac',\n",
       " 'aoife',\n",
       " 'aorta',\n",
       " 'aotea',\n",
       " 'aotes',\n",
       " 'aotus',\n",
       " 'aouad',\n",
       " 'apace',\n",
       " 'apaid',\n",
       " 'apair',\n",
       " 'apama',\n",
       " 'apart',\n",
       " 'apass',\n",
       " 'apast',\n",
       " 'apeak',\n",
       " 'apeek',\n",
       " 'apery',\n",
       " 'apers',\n",
       " 'apert',\n",
       " 'aperu',\n",
       " 'aphid',\n",
       " 'aphis',\n",
       " 'aphra',\n",
       " 'apian',\n",
       " 'apiin',\n",
       " 'apili',\n",
       " 'apina',\n",
       " 'aping',\n",
       " 'apiol',\n",
       " 'apios',\n",
       " 'apish',\n",
       " 'apism',\n",
       " 'apium',\n",
       " 'apnea',\n",
       " 'apoda',\n",
       " 'apods',\n",
       " 'apoop',\n",
       " 'aport',\n",
       " 'apout',\n",
       " 'appay',\n",
       " 'appal',\n",
       " 'appar',\n",
       " 'appel',\n",
       " 'appet',\n",
       " 'apple',\n",
       " 'apply',\n",
       " 'appmt',\n",
       " 'appro',\n",
       " 'apptd',\n",
       " 'appui',\n",
       " 'apres',\n",
       " 'april',\n",
       " 'apron',\n",
       " 'apses',\n",
       " 'apsid',\n",
       " 'apsis',\n",
       " 'aptal',\n",
       " 'apter',\n",
       " 'aptly',\n",
       " 'aquae',\n",
       " 'aquas',\n",
       " 'araba',\n",
       " 'araby',\n",
       " 'arabs',\n",
       " 'araca',\n",
       " 'arace',\n",
       " 'arach',\n",
       " 'arado',\n",
       " 'arage',\n",
       " 'arain',\n",
       " 'arake',\n",
       " 'araks',\n",
       " 'aramu',\n",
       " 'arank',\n",
       " 'arara',\n",
       " 'araru',\n",
       " 'arase',\n",
       " 'arati',\n",
       " 'araua',\n",
       " 'arawa',\n",
       " 'arber',\n",
       " 'arbor',\n",
       " 'arcae',\n",
       " 'arced',\n",
       " 'arces',\n",
       " 'archd',\n",
       " 'arche',\n",
       " 'archy',\n",
       " 'archt',\n",
       " 'arcos',\n",
       " 'arcus',\n",
       " 'ardea',\n",
       " 'ardeb',\n",
       " 'arder',\n",
       " 'ardor',\n",
       " 'ardri',\n",
       " 'aread',\n",
       " 'areae',\n",
       " 'areal',\n",
       " 'arean',\n",
       " 'arear',\n",
       " 'areas',\n",
       " 'areca',\n",
       " 'areek',\n",
       " 'areel',\n",
       " 'arefy',\n",
       " 'areic',\n",
       " 'arena',\n",
       " 'arend',\n",
       " 'areng',\n",
       " 'arent',\n",
       " 'arere',\n",
       " 'arest',\n",
       " 'arete',\n",
       " 'argal',\n",
       " 'argan',\n",
       " 'argas',\n",
       " 'argel',\n",
       " 'argid',\n",
       " 'argil',\n",
       " 'argin',\n",
       " 'argle',\n",
       " 'argol',\n",
       " 'argon',\n",
       " 'argos',\n",
       " 'argot',\n",
       " 'argue',\n",
       " 'argus',\n",
       " 'arhar',\n",
       " 'arhat',\n",
       " 'arian',\n",
       " 'aryan',\n",
       " 'arias',\n",
       " 'ariel',\n",
       " 'aries',\n",
       " 'ariki',\n",
       " 'arils',\n",
       " 'aryls',\n",
       " 'arioi',\n",
       " 'arion',\n",
       " 'ariot',\n",
       " 'arise',\n",
       " 'arish',\n",
       " 'arist',\n",
       " 'arite',\n",
       " 'arith',\n",
       " 'arius',\n",
       " 'arjun',\n",
       " 'arkab',\n",
       " 'arkie',\n",
       " 'arles',\n",
       " 'armed',\n",
       " 'armer',\n",
       " 'armet',\n",
       " 'armil',\n",
       " 'armit',\n",
       " 'armor',\n",
       " 'arneb',\n",
       " 'arnee',\n",
       " 'arnut',\n",
       " 'aroar',\n",
       " 'arock',\n",
       " 'aroid',\n",
       " 'aroma',\n",
       " 'aroon',\n",
       " 'aroph',\n",
       " 'arose',\n",
       " 'arpen',\n",
       " 'arrah',\n",
       " 'array',\n",
       " 'arras',\n",
       " 'arrau',\n",
       " 'arret',\n",
       " 'arrgt',\n",
       " 'arrha',\n",
       " 'arrie',\n",
       " 'arris',\n",
       " 'arrow',\n",
       " 'arroz',\n",
       " 'arses',\n",
       " 'arsyl',\n",
       " 'arsis',\n",
       " 'arsle',\n",
       " 'arson',\n",
       " 'artal',\n",
       " 'artar',\n",
       " 'artel',\n",
       " 'arter',\n",
       " 'artha',\n",
       " 'artic',\n",
       " 'artie',\n",
       " 'artly',\n",
       " 'artou',\n",
       " 'artsy',\n",
       " 'artus',\n",
       " 'aruac',\n",
       " 'aruke',\n",
       " 'arulo',\n",
       " 'arums',\n",
       " 'arupa',\n",
       " 'arusa',\n",
       " 'arval',\n",
       " 'arvel',\n",
       " 'arvos',\n",
       " 'arzan',\n",
       " 'arzun',\n",
       " 'asale',\n",
       " 'asana',\n",
       " 'asaph',\n",
       " 'asarh',\n",
       " 'ascan',\n",
       " 'ascii',\n",
       " 'ascon',\n",
       " 'ascot',\n",
       " 'ascry',\n",
       " 'ascus',\n",
       " 'asdic',\n",
       " 'asgmt',\n",
       " 'ashed',\n",
       " 'ashen',\n",
       " 'asher',\n",
       " 'ashes',\n",
       " 'ashet',\n",
       " 'ashir',\n",
       " 'ashot',\n",
       " 'ashur',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'asyla',\n",
       " 'asyle',\n",
       " 'async',\n",
       " 'askar',\n",
       " 'asked',\n",
       " 'asker',\n",
       " 'askew',\n",
       " 'askip',\n",
       " 'askoi',\n",
       " 'askos',\n",
       " 'aslop',\n",
       " 'asoak',\n",
       " 'asoka',\n",
       " 'aspca',\n",
       " 'aspen',\n",
       " 'asper',\n",
       " 'aspic',\n",
       " 'aspis',\n",
       " 'assai',\n",
       " 'assay',\n",
       " 'assam',\n",
       " 'asses',\n",
       " 'asset',\n",
       " 'assis',\n",
       " 'assoc',\n",
       " 'assot',\n",
       " 'astay',\n",
       " 'astel',\n",
       " 'aster',\n",
       " 'astir',\n",
       " 'astor',\n",
       " 'astre',\n",
       " 'astur',\n",
       " 'asuri',\n",
       " 'asway',\n",
       " 'aswim',\n",
       " 'atake',\n",
       " 'atame',\n",
       " 'atavi',\n",
       " ...]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in lines:\n",
    "    if len(i) == 5:\n",
    "        wordle_list.append(i)\n",
    "        \n",
    "wordle_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "62d06bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       words\n",
      "0      aahed\n",
      "1      aalii\n",
      "2      aargh\n",
      "3      aaron\n",
      "4      abaca\n",
      "...      ...\n",
      "15915  zowie\n",
      "15916  zucco\n",
      "15917  zudda\n",
      "15918  zulus\n",
      "15919  zunis\n",
      "\n",
      "[15920 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(wordle_list, columns =['words'], dtype = str) \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6e26589a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aahed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aalii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aargh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abaca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   words\n",
       "0  aahed\n",
       "1  aalii\n",
       "2  aargh\n",
       "3  aaron\n",
       "4  abaca"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3a1cb27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['letters'] = df['words'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d5cbe526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_word_into_letters(word):\n",
    "    return list(word)\n",
    "\n",
    "# Apply the function to each row and create new columns for each letter\n",
    "for index, row in df.iterrows():\n",
    "    word = row['words']\n",
    "    letters = split_word_into_letters(word)\n",
    "    for i, letter in enumerate(letters):\n",
    "        df.at[index, f'letter_{i+1}'] = letter\n",
    "\n",
    "# Drop the original 'words' column if you no longer need it\n",
    "#df.drop('words', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95527ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5513df0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>letters</th>\n",
       "      <th>letter_1</th>\n",
       "      <th>letter_2</th>\n",
       "      <th>letter_3</th>\n",
       "      <th>letter_4</th>\n",
       "      <th>letter_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aahed</td>\n",
       "      <td>[a, a, h, e, d]</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>h</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aalii</td>\n",
       "      <td>[a, a, l, i, i]</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aargh</td>\n",
       "      <td>[a, a, r, g, h]</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>g</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaron</td>\n",
       "      <td>[a, a, r, o, n]</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abaca</td>\n",
       "      <td>[a, b, a, c, a]</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   words          letters letter_1 letter_2 letter_3 letter_4 letter_5\n",
       "0  aahed  [a, a, h, e, d]        a        a        h        e        d\n",
       "1  aalii  [a, a, l, i, i]        a        a        l        i        i\n",
       "2  aargh  [a, a, r, g, h]        a        a        r        g        h\n",
       "3  aaron  [a, a, r, o, n]        a        a        r        o        n\n",
       "4  abaca  [a, b, a, c, a]        a        b        a        c        a"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dd1e5103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['letter_1_freq'] = df['letter_1'].map(df['letter_1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "07fe1073",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['letter_2_freq'] = df['letter_2'].map(df['letter_2'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0eb7e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['letter_3_freq'] = df['letter_3'].map(df['letter_3'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c32f32ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['letter_4_freq'] = df['letter_4'].map(df['letter_4'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefdbbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ad847dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['letter_5_freq'] = df['letter_5'].map(df['letter_5'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0da72d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>letters</th>\n",
       "      <th>letter_1</th>\n",
       "      <th>letter_2</th>\n",
       "      <th>letter_3</th>\n",
       "      <th>letter_4</th>\n",
       "      <th>letter_5</th>\n",
       "      <th>letter_1_freq</th>\n",
       "      <th>letter_2_freq</th>\n",
       "      <th>letter_3_freq</th>\n",
       "      <th>letter_4_freq</th>\n",
       "      <th>letter_5_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aahed</td>\n",
       "      <td>[a, a, h, e, d]</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>h</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>1174</td>\n",
       "      <td>2871</td>\n",
       "      <td>208</td>\n",
       "      <td>2510</td>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aalii</td>\n",
       "      <td>[a, a, l, i, i]</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>1174</td>\n",
       "      <td>2871</td>\n",
       "      <td>1061</td>\n",
       "      <td>1321</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aargh</td>\n",
       "      <td>[a, a, r, g, h]</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>g</td>\n",
       "      <td>h</td>\n",
       "      <td>1174</td>\n",
       "      <td>2871</td>\n",
       "      <td>1545</td>\n",
       "      <td>477</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaron</td>\n",
       "      <td>[a, a, r, o, n]</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>n</td>\n",
       "      <td>1174</td>\n",
       "      <td>2871</td>\n",
       "      <td>1545</td>\n",
       "      <td>903</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abaca</td>\n",
       "      <td>[a, b, a, c, a]</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1174</td>\n",
       "      <td>109</td>\n",
       "      <td>1481</td>\n",
       "      <td>542</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   words          letters letter_1 letter_2 letter_3 letter_4 letter_5  \\\n",
       "0  aahed  [a, a, h, e, d]        a        a        h        e        d   \n",
       "1  aalii  [a, a, l, i, i]        a        a        l        i        i   \n",
       "2  aargh  [a, a, r, g, h]        a        a        r        g        h   \n",
       "3  aaron  [a, a, r, o, n]        a        a        r        o        n   \n",
       "4  abaca  [a, b, a, c, a]        a        b        a        c        a   \n",
       "\n",
       "   letter_1_freq  letter_2_freq  letter_3_freq  letter_4_freq  letter_5_freq  \n",
       "0           1174           2871            208           2510            817  \n",
       "1           1174           2871           1061           1321            509  \n",
       "2           1174           2871           1545            477            497  \n",
       "3           1174           2871           1545            903            909  \n",
       "4           1174            109           1481            542           1282  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc40839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "09081d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CumWeight'] = df['letter_1_freq']+ df['letter_2_freq'] + df['letter_3_freq'] + df['letter_4_freq'] + df['letter_5_freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "941d9cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>letters</th>\n",
       "      <th>letter_1</th>\n",
       "      <th>letter_2</th>\n",
       "      <th>letter_3</th>\n",
       "      <th>letter_4</th>\n",
       "      <th>letter_5</th>\n",
       "      <th>letter_1_freq</th>\n",
       "      <th>letter_2_freq</th>\n",
       "      <th>letter_3_freq</th>\n",
       "      <th>letter_4_freq</th>\n",
       "      <th>letter_5_freq</th>\n",
       "      <th>CumWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12031</th>\n",
       "      <td>sanes</td>\n",
       "      <td>[s, a, n, e, s]</td>\n",
       "      <td>s</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>1813</td>\n",
       "      <td>2871</td>\n",
       "      <td>1238</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>11580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11985</th>\n",
       "      <td>sales</td>\n",
       "      <td>[s, a, l, e, s]</td>\n",
       "      <td>s</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>1813</td>\n",
       "      <td>2871</td>\n",
       "      <td>1061</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>11403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13119</th>\n",
       "      <td>sores</td>\n",
       "      <td>[s, o, r, e, s]</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>1813</td>\n",
       "      <td>2281</td>\n",
       "      <td>1545</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>11297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>cares</td>\n",
       "      <td>[c, a, r, e, s]</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>1196</td>\n",
       "      <td>2871</td>\n",
       "      <td>1545</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>11270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>bares</td>\n",
       "      <td>[b, a, r, e, s]</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>1141</td>\n",
       "      <td>2871</td>\n",
       "      <td>1545</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>11215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       words          letters letter_1 letter_2 letter_3 letter_4 letter_5  \\\n",
       "12031  sanes  [s, a, n, e, s]        s        a        n        e        s   \n",
       "11985  sales  [s, a, l, e, s]        s        a        l        e        s   \n",
       "13119  sores  [s, o, r, e, s]        s        o        r        e        s   \n",
       "2472   cares  [c, a, r, e, s]        c        a        r        e        s   \n",
       "1324   bares  [b, a, r, e, s]        b        a        r        e        s   \n",
       "\n",
       "       letter_1_freq  letter_2_freq  letter_3_freq  letter_4_freq  \\\n",
       "12031           1813           2871           1238           2510   \n",
       "11985           1813           2871           1061           2510   \n",
       "13119           1813           2281           1545           2510   \n",
       "2472            1196           2871           1545           2510   \n",
       "1324            1141           2871           1545           2510   \n",
       "\n",
       "       letter_5_freq  CumWeight  \n",
       "12031           3148      11580  \n",
       "11985           3148      11403  \n",
       "13119           3148      11297  \n",
       "2472            3148      11270  \n",
       "1324            3148      11215  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_guess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ced8a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_guess = df.sort_values('CumWeight',  ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2814363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = df_guess['words'].iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "52a23d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = list(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28272693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d2d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e93e7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_guess = guess[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "482b87f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s', 'a', 'n', 'e', 's']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lst_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6c1e1bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_guess[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d5dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2a496815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12031    a\n",
       "11985    a\n",
       "13119    o\n",
       "2472     a\n",
       "1324     a\n",
       "        ..\n",
       "4691     w\n",
       "6809     d\n",
       "15883    m\n",
       "4558     n\n",
       "9936     g\n",
       "Name: letter_2, Length: 15920, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_guess['letter_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "78b12cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>letters</th>\n",
       "      <th>letter_1</th>\n",
       "      <th>letter_2</th>\n",
       "      <th>letter_3</th>\n",
       "      <th>letter_4</th>\n",
       "      <th>letter_5</th>\n",
       "      <th>letter_1_freq</th>\n",
       "      <th>letter_2_freq</th>\n",
       "      <th>letter_3_freq</th>\n",
       "      <th>letter_4_freq</th>\n",
       "      <th>letter_5_freq</th>\n",
       "      <th>CumWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9523</th>\n",
       "      <td>nares</td>\n",
       "      <td>[n, a, r, e, s]</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>406</td>\n",
       "      <td>2871</td>\n",
       "      <td>1545</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>10480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9504</th>\n",
       "      <td>nanes</td>\n",
       "      <td>[n, a, n, e, s]</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>406</td>\n",
       "      <td>2871</td>\n",
       "      <td>1238</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>10173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9539</th>\n",
       "      <td>nates</td>\n",
       "      <td>[n, a, t, e, s]</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>406</td>\n",
       "      <td>2871</td>\n",
       "      <td>783</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>9718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>names</td>\n",
       "      <td>[n, a, m, e, s]</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>406</td>\n",
       "      <td>2871</td>\n",
       "      <td>649</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>9584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9767</th>\n",
       "      <td>nones</td>\n",
       "      <td>[n, o, n, e, s]</td>\n",
       "      <td>n</td>\n",
       "      <td>o</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>406</td>\n",
       "      <td>2281</td>\n",
       "      <td>1238</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>9583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9693</th>\n",
       "      <td>nyoro</td>\n",
       "      <td>[n, y, o, r, o]</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>406</td>\n",
       "      <td>279</td>\n",
       "      <td>1154</td>\n",
       "      <td>872</td>\n",
       "      <td>547</td>\n",
       "      <td>3258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9832</th>\n",
       "      <td>nudzh</td>\n",
       "      <td>[n, u, d, z, h]</td>\n",
       "      <td>n</td>\n",
       "      <td>u</td>\n",
       "      <td>d</td>\n",
       "      <td>z</td>\n",
       "      <td>h</td>\n",
       "      <td>406</td>\n",
       "      <td>1403</td>\n",
       "      <td>514</td>\n",
       "      <td>129</td>\n",
       "      <td>497</td>\n",
       "      <td>2949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9636</th>\n",
       "      <td>ngapi</td>\n",
       "      <td>[n, g, a, p, i]</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>a</td>\n",
       "      <td>p</td>\n",
       "      <td>i</td>\n",
       "      <td>406</td>\n",
       "      <td>102</td>\n",
       "      <td>1481</td>\n",
       "      <td>424</td>\n",
       "      <td>509</td>\n",
       "      <td>2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9637</th>\n",
       "      <td>ngoko</td>\n",
       "      <td>[n, g, o, k, o]</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>o</td>\n",
       "      <td>k</td>\n",
       "      <td>o</td>\n",
       "      <td>406</td>\n",
       "      <td>102</td>\n",
       "      <td>1154</td>\n",
       "      <td>484</td>\n",
       "      <td>547</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9681</th>\n",
       "      <td>nymph</td>\n",
       "      <td>[n, y, m, p, h]</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>m</td>\n",
       "      <td>p</td>\n",
       "      <td>h</td>\n",
       "      <td>406</td>\n",
       "      <td>279</td>\n",
       "      <td>649</td>\n",
       "      <td>424</td>\n",
       "      <td>497</td>\n",
       "      <td>2255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      words          letters letter_1 letter_2 letter_3 letter_4 letter_5  \\\n",
       "9523  nares  [n, a, r, e, s]        n        a        r        e        s   \n",
       "9504  nanes  [n, a, n, e, s]        n        a        n        e        s   \n",
       "9539  nates  [n, a, t, e, s]        n        a        t        e        s   \n",
       "9495  names  [n, a, m, e, s]        n        a        m        e        s   \n",
       "9767  nones  [n, o, n, e, s]        n        o        n        e        s   \n",
       "...     ...              ...      ...      ...      ...      ...      ...   \n",
       "9693  nyoro  [n, y, o, r, o]        n        y        o        r        o   \n",
       "9832  nudzh  [n, u, d, z, h]        n        u        d        z        h   \n",
       "9636  ngapi  [n, g, a, p, i]        n        g        a        p        i   \n",
       "9637  ngoko  [n, g, o, k, o]        n        g        o        k        o   \n",
       "9681  nymph  [n, y, m, p, h]        n        y        m        p        h   \n",
       "\n",
       "      letter_1_freq  letter_2_freq  letter_3_freq  letter_4_freq  \\\n",
       "9523            406           2871           1545           2510   \n",
       "9504            406           2871           1238           2510   \n",
       "9539            406           2871            783           2510   \n",
       "9495            406           2871            649           2510   \n",
       "9767            406           2281           1238           2510   \n",
       "...             ...            ...            ...            ...   \n",
       "9693            406            279           1154            872   \n",
       "9832            406           1403            514            129   \n",
       "9636            406            102           1481            424   \n",
       "9637            406            102           1154            484   \n",
       "9681            406            279            649            424   \n",
       "\n",
       "      letter_5_freq  CumWeight  \n",
       "9523           3148      10480  \n",
       "9504           3148      10173  \n",
       "9539           3148       9718  \n",
       "9495           3148       9584  \n",
       "9767           3148       9583  \n",
       "...             ...        ...  \n",
       "9693            547       3258  \n",
       "9832            497       2949  \n",
       "9636            509       2922  \n",
       "9637            547       2693  \n",
       "9681            497       2255  \n",
       "\n",
       "[406 rows x 13 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_guess.loc[df_guess['letter_' + str(count+1)] == 'n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84205a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6044e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c0fbd4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>letters</th>\n",
       "      <th>letter_1</th>\n",
       "      <th>letter_2</th>\n",
       "      <th>letter_3</th>\n",
       "      <th>letter_4</th>\n",
       "      <th>letter_5</th>\n",
       "      <th>letter_1_freq</th>\n",
       "      <th>letter_2_freq</th>\n",
       "      <th>letter_3_freq</th>\n",
       "      <th>letter_4_freq</th>\n",
       "      <th>letter_5_freq</th>\n",
       "      <th>CumWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9523</th>\n",
       "      <td>nares</td>\n",
       "      <td>[n, a, r, e, s]</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>406</td>\n",
       "      <td>2871</td>\n",
       "      <td>1545</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>10480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9504</th>\n",
       "      <td>nanes</td>\n",
       "      <td>[n, a, n, e, s]</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>406</td>\n",
       "      <td>2871</td>\n",
       "      <td>1238</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>10173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9539</th>\n",
       "      <td>nates</td>\n",
       "      <td>[n, a, t, e, s]</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>406</td>\n",
       "      <td>2871</td>\n",
       "      <td>783</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>9718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>names</td>\n",
       "      <td>[n, a, m, e, s]</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>406</td>\n",
       "      <td>2871</td>\n",
       "      <td>649</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>9584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9767</th>\n",
       "      <td>nones</td>\n",
       "      <td>[n, o, n, e, s]</td>\n",
       "      <td>n</td>\n",
       "      <td>o</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>406</td>\n",
       "      <td>2281</td>\n",
       "      <td>1238</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>9583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9693</th>\n",
       "      <td>nyoro</td>\n",
       "      <td>[n, y, o, r, o]</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "      <td>406</td>\n",
       "      <td>279</td>\n",
       "      <td>1154</td>\n",
       "      <td>872</td>\n",
       "      <td>547</td>\n",
       "      <td>3258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9832</th>\n",
       "      <td>nudzh</td>\n",
       "      <td>[n, u, d, z, h]</td>\n",
       "      <td>n</td>\n",
       "      <td>u</td>\n",
       "      <td>d</td>\n",
       "      <td>z</td>\n",
       "      <td>h</td>\n",
       "      <td>406</td>\n",
       "      <td>1403</td>\n",
       "      <td>514</td>\n",
       "      <td>129</td>\n",
       "      <td>497</td>\n",
       "      <td>2949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9636</th>\n",
       "      <td>ngapi</td>\n",
       "      <td>[n, g, a, p, i]</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>a</td>\n",
       "      <td>p</td>\n",
       "      <td>i</td>\n",
       "      <td>406</td>\n",
       "      <td>102</td>\n",
       "      <td>1481</td>\n",
       "      <td>424</td>\n",
       "      <td>509</td>\n",
       "      <td>2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9637</th>\n",
       "      <td>ngoko</td>\n",
       "      <td>[n, g, o, k, o]</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>o</td>\n",
       "      <td>k</td>\n",
       "      <td>o</td>\n",
       "      <td>406</td>\n",
       "      <td>102</td>\n",
       "      <td>1154</td>\n",
       "      <td>484</td>\n",
       "      <td>547</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9681</th>\n",
       "      <td>nymph</td>\n",
       "      <td>[n, y, m, p, h]</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>m</td>\n",
       "      <td>p</td>\n",
       "      <td>h</td>\n",
       "      <td>406</td>\n",
       "      <td>279</td>\n",
       "      <td>649</td>\n",
       "      <td>424</td>\n",
       "      <td>497</td>\n",
       "      <td>2255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      words          letters letter_1 letter_2 letter_3 letter_4 letter_5  \\\n",
       "9523  nares  [n, a, r, e, s]        n        a        r        e        s   \n",
       "9504  nanes  [n, a, n, e, s]        n        a        n        e        s   \n",
       "9539  nates  [n, a, t, e, s]        n        a        t        e        s   \n",
       "9495  names  [n, a, m, e, s]        n        a        m        e        s   \n",
       "9767  nones  [n, o, n, e, s]        n        o        n        e        s   \n",
       "...     ...              ...      ...      ...      ...      ...      ...   \n",
       "9693  nyoro  [n, y, o, r, o]        n        y        o        r        o   \n",
       "9832  nudzh  [n, u, d, z, h]        n        u        d        z        h   \n",
       "9636  ngapi  [n, g, a, p, i]        n        g        a        p        i   \n",
       "9637  ngoko  [n, g, o, k, o]        n        g        o        k        o   \n",
       "9681  nymph  [n, y, m, p, h]        n        y        m        p        h   \n",
       "\n",
       "      letter_1_freq  letter_2_freq  letter_3_freq  letter_4_freq  \\\n",
       "9523            406           2871           1545           2510   \n",
       "9504            406           2871           1238           2510   \n",
       "9539            406           2871            783           2510   \n",
       "9495            406           2871            649           2510   \n",
       "9767            406           2281           1238           2510   \n",
       "...             ...            ...            ...            ...   \n",
       "9693            406            279           1154            872   \n",
       "9832            406           1403            514            129   \n",
       "9636            406            102           1481            424   \n",
       "9637            406            102           1154            484   \n",
       "9681            406            279            649            424   \n",
       "\n",
       "      letter_5_freq  CumWeight  \n",
       "9523           3148      10480  \n",
       "9504           3148      10173  \n",
       "9539           3148       9718  \n",
       "9495           3148       9584  \n",
       "9767           3148       9583  \n",
       "...             ...        ...  \n",
       "9693            547       3258  \n",
       "9832            497       2949  \n",
       "9636            509       2922  \n",
       "9637            547       2693  \n",
       "9681            497       2255  \n",
       "\n",
       "[406 rows x 13 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_guess.loc[df_guess['letter_' + str(count+1)] == 'n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "49159cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "go = df_guess.loc[df_guess['letter_' + str(count+2)] == 'n']\n",
    "df_drop = df_guess.drop(df_guess.loc[df_guess['letter_' + str(count+2)] == 'n'].index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "11e5bee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>letters</th>\n",
       "      <th>letter_1</th>\n",
       "      <th>letter_2</th>\n",
       "      <th>letter_3</th>\n",
       "      <th>letter_4</th>\n",
       "      <th>letter_5</th>\n",
       "      <th>letter_1_freq</th>\n",
       "      <th>letter_2_freq</th>\n",
       "      <th>letter_3_freq</th>\n",
       "      <th>letter_4_freq</th>\n",
       "      <th>letter_5_freq</th>\n",
       "      <th>CumWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11985</th>\n",
       "      <td>sales</td>\n",
       "      <td>[s, a, l, e, s]</td>\n",
       "      <td>s</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>1813</td>\n",
       "      <td>2871</td>\n",
       "      <td>1061</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>11403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13119</th>\n",
       "      <td>sores</td>\n",
       "      <td>[s, o, r, e, s]</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>1813</td>\n",
       "      <td>2281</td>\n",
       "      <td>1545</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>11297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>cares</td>\n",
       "      <td>[c, a, r, e, s]</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>1196</td>\n",
       "      <td>2871</td>\n",
       "      <td>1545</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>11270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>bares</td>\n",
       "      <td>[b, a, r, e, s]</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>1141</td>\n",
       "      <td>2871</td>\n",
       "      <td>1545</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>11215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12082</th>\n",
       "      <td>sates</td>\n",
       "      <td>[s, a, t, e, s]</td>\n",
       "      <td>s</td>\n",
       "      <td>a</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>1813</td>\n",
       "      <td>2871</td>\n",
       "      <td>783</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>11125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       words          letters letter_1 letter_2 letter_3 letter_4 letter_5  \\\n",
       "11985  sales  [s, a, l, e, s]        s        a        l        e        s   \n",
       "13119  sores  [s, o, r, e, s]        s        o        r        e        s   \n",
       "2472   cares  [c, a, r, e, s]        c        a        r        e        s   \n",
       "1324   bares  [b, a, r, e, s]        b        a        r        e        s   \n",
       "12082  sates  [s, a, t, e, s]        s        a        t        e        s   \n",
       "\n",
       "       letter_1_freq  letter_2_freq  letter_3_freq  letter_4_freq  \\\n",
       "11985           1813           2871           1061           2510   \n",
       "13119           1813           2281           1545           2510   \n",
       "2472            1196           2871           1545           2510   \n",
       "1324            1141           2871           1545           2510   \n",
       "12082           1813           2871            783           2510   \n",
       "\n",
       "       letter_5_freq  CumWeight  \n",
       "11985           3148      11403  \n",
       "13119           3148      11297  \n",
       "2472            3148      11270  \n",
       "1324            3148      11215  \n",
       "12082           3148      11125  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9f6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a0354dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>letters</th>\n",
       "      <th>letter_1</th>\n",
       "      <th>letter_2</th>\n",
       "      <th>letter_3</th>\n",
       "      <th>letter_4</th>\n",
       "      <th>letter_5</th>\n",
       "      <th>letter_1_freq</th>\n",
       "      <th>letter_2_freq</th>\n",
       "      <th>letter_3_freq</th>\n",
       "      <th>letter_4_freq</th>\n",
       "      <th>letter_5_freq</th>\n",
       "      <th>CumWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12031</th>\n",
       "      <td>sanes</td>\n",
       "      <td>[s, a, n, e, s]</td>\n",
       "      <td>s</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>1813</td>\n",
       "      <td>2871</td>\n",
       "      <td>1238</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>11580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11985</th>\n",
       "      <td>sales</td>\n",
       "      <td>[s, a, l, e, s]</td>\n",
       "      <td>s</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>1813</td>\n",
       "      <td>2871</td>\n",
       "      <td>1061</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>11403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13119</th>\n",
       "      <td>sores</td>\n",
       "      <td>[s, o, r, e, s]</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>1813</td>\n",
       "      <td>2281</td>\n",
       "      <td>1545</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>11297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>cares</td>\n",
       "      <td>[c, a, r, e, s]</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>1196</td>\n",
       "      <td>2871</td>\n",
       "      <td>1545</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>11270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>bares</td>\n",
       "      <td>[b, a, r, e, s]</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>s</td>\n",
       "      <td>1141</td>\n",
       "      <td>2871</td>\n",
       "      <td>1545</td>\n",
       "      <td>2510</td>\n",
       "      <td>3148</td>\n",
       "      <td>11215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       words          letters letter_1 letter_2 letter_3 letter_4 letter_5  \\\n",
       "12031  sanes  [s, a, n, e, s]        s        a        n        e        s   \n",
       "11985  sales  [s, a, l, e, s]        s        a        l        e        s   \n",
       "13119  sores  [s, o, r, e, s]        s        o        r        e        s   \n",
       "2472   cares  [c, a, r, e, s]        c        a        r        e        s   \n",
       "1324   bares  [b, a, r, e, s]        b        a        r        e        s   \n",
       "\n",
       "       letter_1_freq  letter_2_freq  letter_3_freq  letter_4_freq  \\\n",
       "12031           1813           2871           1238           2510   \n",
       "11985           1813           2871           1061           2510   \n",
       "13119           1813           2281           1545           2510   \n",
       "2472            1196           2871           1545           2510   \n",
       "1324            1141           2871           1545           2510   \n",
       "\n",
       "       letter_5_freq  CumWeight  \n",
       "12031           3148      11580  \n",
       "11985           3148      11403  \n",
       "13119           3148      11297  \n",
       "2472            3148      11270  \n",
       "1324            3148      11215  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_guess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec305b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4c51e51d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>letters</th>\n",
       "      <th>letter_1</th>\n",
       "      <th>letter_2</th>\n",
       "      <th>letter_3</th>\n",
       "      <th>letter_4</th>\n",
       "      <th>letter_5</th>\n",
       "      <th>letter_1_freq</th>\n",
       "      <th>letter_2_freq</th>\n",
       "      <th>letter_3_freq</th>\n",
       "      <th>letter_4_freq</th>\n",
       "      <th>letter_5_freq</th>\n",
       "      <th>CumWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>baaed</td>\n",
       "      <td>[b, a, a, e, d]</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>1141</td>\n",
       "      <td>2871</td>\n",
       "      <td>1481</td>\n",
       "      <td>2510</td>\n",
       "      <td>817</td>\n",
       "      <td>8820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>baals</td>\n",
       "      <td>[b, a, a, l, s]</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>s</td>\n",
       "      <td>1141</td>\n",
       "      <td>2871</td>\n",
       "      <td>1481</td>\n",
       "      <td>923</td>\n",
       "      <td>3148</td>\n",
       "      <td>9564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>babai</td>\n",
       "      <td>[b, a, b, a, i]</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>1141</td>\n",
       "      <td>2871</td>\n",
       "      <td>446</td>\n",
       "      <td>1585</td>\n",
       "      <td>509</td>\n",
       "      <td>6552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>babas</td>\n",
       "      <td>[b, a, b, a, s]</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>s</td>\n",
       "      <td>1141</td>\n",
       "      <td>2871</td>\n",
       "      <td>446</td>\n",
       "      <td>1585</td>\n",
       "      <td>3148</td>\n",
       "      <td>9191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>babby</td>\n",
       "      <td>[b, a, b, b, y]</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>1141</td>\n",
       "      <td>2871</td>\n",
       "      <td>446</td>\n",
       "      <td>297</td>\n",
       "      <td>1686</td>\n",
       "      <td>6441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15915</th>\n",
       "      <td>zowie</td>\n",
       "      <td>[z, o, w, i, e]</td>\n",
       "      <td>z</td>\n",
       "      <td>o</td>\n",
       "      <td>w</td>\n",
       "      <td>i</td>\n",
       "      <td>e</td>\n",
       "      <td>112</td>\n",
       "      <td>2281</td>\n",
       "      <td>276</td>\n",
       "      <td>1321</td>\n",
       "      <td>1873</td>\n",
       "      <td>5863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15916</th>\n",
       "      <td>zucco</td>\n",
       "      <td>[z, u, c, c, o]</td>\n",
       "      <td>z</td>\n",
       "      <td>u</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>o</td>\n",
       "      <td>112</td>\n",
       "      <td>1403</td>\n",
       "      <td>531</td>\n",
       "      <td>542</td>\n",
       "      <td>547</td>\n",
       "      <td>3135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15917</th>\n",
       "      <td>zudda</td>\n",
       "      <td>[z, u, d, d, a]</td>\n",
       "      <td>z</td>\n",
       "      <td>u</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "      <td>112</td>\n",
       "      <td>1403</td>\n",
       "      <td>514</td>\n",
       "      <td>545</td>\n",
       "      <td>1282</td>\n",
       "      <td>3856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15918</th>\n",
       "      <td>zulus</td>\n",
       "      <td>[z, u, l, u, s]</td>\n",
       "      <td>z</td>\n",
       "      <td>u</td>\n",
       "      <td>l</td>\n",
       "      <td>u</td>\n",
       "      <td>s</td>\n",
       "      <td>112</td>\n",
       "      <td>1403</td>\n",
       "      <td>1061</td>\n",
       "      <td>686</td>\n",
       "      <td>3148</td>\n",
       "      <td>6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15919</th>\n",
       "      <td>zunis</td>\n",
       "      <td>[z, u, n, i, s]</td>\n",
       "      <td>z</td>\n",
       "      <td>u</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>s</td>\n",
       "      <td>112</td>\n",
       "      <td>1403</td>\n",
       "      <td>1238</td>\n",
       "      <td>1321</td>\n",
       "      <td>3148</td>\n",
       "      <td>7222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14746 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       words          letters letter_1 letter_2 letter_3 letter_4 letter_5  \\\n",
       "1174   baaed  [b, a, a, e, d]        b        a        a        e        d   \n",
       "1175   baals  [b, a, a, l, s]        b        a        a        l        s   \n",
       "1176   babai  [b, a, b, a, i]        b        a        b        a        i   \n",
       "1177   babas  [b, a, b, a, s]        b        a        b        a        s   \n",
       "1178   babby  [b, a, b, b, y]        b        a        b        b        y   \n",
       "...      ...              ...      ...      ...      ...      ...      ...   \n",
       "15915  zowie  [z, o, w, i, e]        z        o        w        i        e   \n",
       "15916  zucco  [z, u, c, c, o]        z        u        c        c        o   \n",
       "15917  zudda  [z, u, d, d, a]        z        u        d        d        a   \n",
       "15918  zulus  [z, u, l, u, s]        z        u        l        u        s   \n",
       "15919  zunis  [z, u, n, i, s]        z        u        n        i        s   \n",
       "\n",
       "       letter_1_freq  letter_2_freq  letter_3_freq  letter_4_freq  \\\n",
       "1174            1141           2871           1481           2510   \n",
       "1175            1141           2871           1481            923   \n",
       "1176            1141           2871            446           1585   \n",
       "1177            1141           2871            446           1585   \n",
       "1178            1141           2871            446            297   \n",
       "...              ...            ...            ...            ...   \n",
       "15915            112           2281            276           1321   \n",
       "15916            112           1403            531            542   \n",
       "15917            112           1403            514            545   \n",
       "15918            112           1403           1061            686   \n",
       "15919            112           1403           1238           1321   \n",
       "\n",
       "       letter_5_freq  CumWeight  \n",
       "1174             817       8820  \n",
       "1175            3148       9564  \n",
       "1176             509       6552  \n",
       "1177            3148       9191  \n",
       "1178            1686       6441  \n",
       "...              ...        ...  \n",
       "15915           1873       5863  \n",
       "15916            547       3135  \n",
       "15917           1282       3856  \n",
       "15918           3148       6410  \n",
       "15919           3148       7222  \n",
       "\n",
       "[14746 rows x 13 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['letter_1'] != 'a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee0df0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "44788be3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-1b2f0b0f5ea6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'G'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mdf_guess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_guess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_guess\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'letter_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlst_guess\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Y'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mdf_guess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_guess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_guess\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'letter_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlst_guess\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not int"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "result = ['G', 'Y', 'R']\n",
    "for i in result:\n",
    "    if i == 'G':\n",
    "        df_guess = df_guess.loc[df_guess['letter_' + count+1] == lst_guess[count]]\n",
    "    if i == 'Y':\n",
    "        df_guess = df_guess.loc[df_guess['letter_' + count+1] != lst_guess[count]]\n",
    "    if i == 'R':\n",
    "        df_guess = df_guess.drop(df_guess.loc[df_guess['letter_' + str(count)] == lst_guess[count]].index.tolist())\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dbf4b93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter_5\n",
       "a    1282\n",
       "b      97\n",
       "c     221\n",
       "d     817\n",
       "e    1873\n",
       "f     101\n",
       "g     194\n",
       "h     497\n",
       "i     509\n",
       "j       2\n",
       "k     376\n",
       "l     718\n",
       "m     297\n",
       "n     909\n",
       "o     547\n",
       "p     214\n",
       "q       3\n",
       "r     895\n",
       "s    3148\n",
       "t    1090\n",
       "u     157\n",
       "v      23\n",
       "w      94\n",
       "x     116\n",
       "y    1686\n",
       "z      54\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['letter_1']).size()\n",
    "df.groupby(['letter_2']).size()\n",
    "df.groupby(['letter_3']).size()\n",
    "df.groupby(['letter_4']).size()\n",
    "df.groupby(['letter_5']).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad85b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee313d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d26b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba2436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089dd196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "08e0f540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df.letter_1, bins = 50)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96190e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b0fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9275fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f55a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199cb1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c2b5cd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Wordle game\n",
      "You have 6 attempts to guess the correct word\n",
      "All the words should be a word that exists in the dictionary and\n",
      "these words are only 5 lettered words.\n"
     ]
    }
   ],
   "source": [
    "welcome = \"Welcome to the Wordle game\\nYou have 6 attempts to guess the correct word\\nAll the words should be a word that exists in the dictionary and\\nthese words are only 5 lettered words.\"\n",
    "\n",
    "print(welcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "48d4de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_wordle_list = [\"apple\", \"mango\", \"catch\", \"match\", \"patch\", \"yatch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "071f7bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from ansi.colour import fg, bg\n",
    "from ansi.colour.fx import reset\n",
    "from colorama import Fore, Back, Style, init as colorama_init\n",
    "from termcolor import colored\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "924ac5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordle_word_to_guess = (np.random.choice(temp_wordle_list))\n",
    "wordle_word_to_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3fe05ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all of this will be in a loop for n = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5f3b5e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Wordle game\n",
      "You have 6 attempts to guess the correct word\n",
      "All the words should be a word that exists in the dictionary and\n",
      "these words are only 5 lettered words.\n",
      "\n",
      "Please make your guess: termc\n",
      "\n",
      "Correct\n",
      "['t', 'e', 'r', 'm', 'c']\n",
      "['p', 'a', 't', 'c', 'h']\n",
      "['t', 'e', 'r', 'm', 'c']\n",
      "Please make your guess: patch\n",
      "\n",
      "Correct\n",
      "['p', 'a', 't', 'c', 'h']\n",
      "['p', 'a', 't', 'c', 'h']\n",
      "['p', 'a', 't', 'c', 'h']\n",
      "Congrats! You got the correct word\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import re\n",
    "from ansi.colour import fg, bg\n",
    "from ansi.colour.fx import reset\n",
    "from colorama import Fore, Back, Style, init as colorama_init\n",
    "#from termcolor import colored\n",
    "\n",
    "\n",
    "welcome = \"Welcome to the Wordle game\\nYou have 6 attempts to guess the correct word\\nAll the words should be a word that exists in the dictionary and\\nthese words are only 5 lettered words.\"\n",
    "\n",
    "print(welcome)\n",
    "\n",
    "\n",
    "temp_wordle_list = [\"apple\", \"mango\", \"catch\", \"match\", \"patch\", \"yatch\"]\n",
    "\n",
    "\n",
    "\n",
    "wordle_word_to_guess = (np.random.choice(temp_wordle_list))\n",
    "wordle_word_to_guess\n",
    "\n",
    "for i in range(6):\n",
    "    \n",
    "    \n",
    "    if i == 5:\n",
    "        print(\"\\n\\nYour last attempt\")\n",
    "        #print(\"\\nYou have made 6 attempts! Sorry, you couldn't guess the word. Better luck next time!\")\n",
    "\n",
    "    guess_input = input(\"\\nPlease make your guess: \")\n",
    "    while True: \n",
    "   \n",
    "        if len(guess_input) == 5 and re.match(\"^[a-zA-Z]*$\", guess_input):\n",
    "                print(\"\\nCorrect\")\n",
    "                break\n",
    "        else:\n",
    "        \n",
    "            print(\"\\nWrong !\")\n",
    "            if not re.match(\"^[a-zA-Z]*$\", guess_input):\n",
    "                print(\"\\nError! Only letters a-z or A-Z allowed!\")\n",
    "            elif len(guess_input) < 5:\n",
    "                print(\"\\nError! There are only\" , len(guess_input) , \"words. Kindly input 5 letters only.\" )\n",
    "            elif len(guess_input) > 5:\n",
    "                print(\"\\nError! There are\" , len(guess_input) ,\"words which is more than 5. Kindly input 5 letters only.\" )\n",
    "            guess_input = input(\"\\nPlease make your guess: \")\n",
    "    \n",
    "    \n",
    "    print(list(guess_input))\n",
    "    print(list(wordle_word_to_guess))\n",
    "\n",
    "    guess_input_letters = list(guess_input)\n",
    "    wordle_word_to_guess_letters = list(wordle_word_to_guess)\n",
    "\n",
    "\n",
    "    result = []   \n",
    "\n",
    "    #guess_input_letters = ['l', 'a', 'l', 'a', 'l']\n",
    "    #wordle_word_to_guess_letters = ['c', 'a', 't', 'c', 'h']\n",
    "    colorama_init()\n",
    "\n",
    "    for i in range(len(guess_input_letters)):\n",
    "        if guess_input_letters[i] == wordle_word_to_guess_letters[i]:\n",
    "            result.append( guess_input_letters[i] )\n",
    "        elif guess_input_letters[i] in wordle_word_to_guess_letters:\n",
    "            result.append( guess_input_letters[i] )\n",
    "        else:\n",
    "            result.append( guess_input_letters[i])\n",
    "            \n",
    "    print(list(result), end = \"\")\n",
    "    \n",
    "    if guess_input_letters == wordle_word_to_guess_letters:\n",
    "        print(\"\\nCongrats! You got the correct word\")\n",
    "        break\n",
    "    elif i == 6 and guess_input_letters != wordle_word_to_guess_letters:\n",
    "        print(\"\\nEnd of Game! Boo!\")\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3baefcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', 'a', 't', 'c', 'h']\n",
      "['p', 'a', 't', 'c', 'h']\n"
     ]
    }
   ],
   "source": [
    "#code continues if no error\n",
    "\n",
    "print(list(guess_input))\n",
    "print(list(wordle_word_to_guess))\n",
    "\n",
    "guess_input_letters = list(guess_input)\n",
    "wordle_word_to_guess_letters = list(wordle_word_to_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "85a9199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [len(set(i)) == 1 for i in zip(wordle_word_to_guess_letters,guess_input_letters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "81a52a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d89a0ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x1b[31ml', '\\x1b[32ma', '\\x1b[31ml', '\\x1b[33ma', '\\x1b[31ml']"
     ]
    }
   ],
   "source": [
    "result = []   \n",
    "\n",
    "guess_input_letters = ['l', 'a', 'l', 'a', 'l']\n",
    "wordle_word_to_guess_letters = ['c', 'a', 't', 'c', 'h']\n",
    "colorama_init()\n",
    "\n",
    "for i in range(len(guess_input_letters)):\n",
    "    if guess_input_letters[i] == wordle_word_to_guess_letters[i]:\n",
    "        result.append( Fore.GREEN + guess_input_letters[i])\n",
    "    elif guess_input_letters[i] in wordle_word_to_guess_letters:\n",
    "        result.append( Fore.YELLOW + guess_input_letters[i] )\n",
    "    else:\n",
    "        result.append( Fore.RED +guess_input_letters[i])\n",
    "\n",
    "\n",
    "print(result, end = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c2c2c020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: HTML in e:\\anaconda3\\env\\cs4811\\lib\\site-packages (1.13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "51840c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "this is in <span style=\"color: #ff0000\">red</span> color."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "display(Markdown('this is in <span style=\"color: #ff0000\">red</span> color.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "19db7ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "hello red world\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "print(colored('hello', 'red'), colored('world', 'green'))\n",
    "print(colored(\"hello red world\", 'red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3e2bd4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x1b[31ml', '\\x1b[32ma', '\\x1b[31ml', '\\x1b[33ma', '\\x1b[31ml']"
     ]
    }
   ],
   "source": [
    "from colorama import Fore, init as colorama_init\n",
    "import os\n",
    "colorama_init()\n",
    "result = []\n",
    "\n",
    "guess_input_letters = ['l', 'a', 'l', 'a', 'l']\n",
    "wordle_word_to_guess_letters = ['c', 'a', 't', 'c', 'h']\n",
    "colorama_init()\n",
    "\n",
    "for i in range(len(guess_input_letters)):\n",
    "    if guess_input_letters[i] == wordle_word_to_guess_letters[i]:\n",
    "        result.append(Fore.GREEN + guess_input_letters[i])\n",
    "    elif guess_input_letters[i] in wordle_word_to_guess_letters:\n",
    "        result.append(Fore.YELLOW + guess_input_letters[i])\n",
    "    else:\n",
    "        result.append(Fore.RED + guess_input_letters[i])\n",
    "os.system(\"cls\" or \"clear\")\n",
    "print(result, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "da341b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if True in x:\n",
    "    print(Fore.GREEN + 'True')\n",
    "if False in x:\n",
    "    print(Fore.RED + 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc386a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8afbf41d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if True in x:\n",
    "    print(Fore.GREEN + 'True')\n",
    "if False in x:\n",
    "    print(Fore.RED + 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "973ff39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x1b[31m1\\x1b[39m', 0, '\\x1b[31m1\\x1b[39m', 0, '\\x1b[31m1\\x1b[39m']\n",
      "1, 0, 1, 0, 1\n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore, Back, Style\n",
    "\n",
    "L = [1,0,1,0,1]\n",
    "for i in range(len(L)):\n",
    "    if L[i] == 1:\n",
    "        L[i] = Fore.RED + str(L[i]) + Fore.RESET\n",
    "print(L)\n",
    "# [0, '\\x1b[31m1\\x1b[39m', 0, '\\x1b[31m1\\x1b[39m', 0, '\\x1b[31m1\\x1b[39m']\n",
    "\n",
    "print(', '.join(str(item) for item in L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "71fb2089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ansi in e:\\anaconda3\\env\\cs4811\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in e:\\anaconda3\\env\\cs4811\\lib\\site-packages (from ansi) (4.1.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install ansi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459db089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dbc9de02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "from ansi.colour import fg, bg\n",
    "from ansi.colour.fx import reset\n",
    "msg = (bg.red, fg.yellow, 'Hello world!', reset)\n",
    "print(''.join(map(str, msg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7671eead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some red text\n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore, Back, Style\n",
    " \n",
    "print(Fore.RED + 'some red text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9033ceda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from colorama import Fore, Back, Style, init\n",
    "init(autoreset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "301ad76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is red text\n",
      "This is green text\n",
      "This is yellow text\n",
      "This is blue text\n",
      "This is magenta text\n",
      "This is cyan text\n",
      "This is white text\n",
      "Back to the default color\n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore, Back, Style, init\n",
    "init(autoreset=True)\n",
    "\n",
    "print(Fore.RED + \"This is red text\")\n",
    "print(Fore.GREEN + \"This is green text\")\n",
    "print(Fore.YELLOW + \"This is yellow text\")\n",
    "print(Fore.BLUE + \"This is blue text\")\n",
    "print(Fore.MAGENTA + \"This is magenta text\")\n",
    "print(Fore.CYAN + \"This is cyan text\")\n",
    "print(Fore.WHITE + \"This is white text\")\n",
    "\n",
    "# You can reset the color with Fore.RESET\n",
    "print(Fore.RESET + \"Back to the default color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda4466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a4f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c289bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d38b6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765501db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "472dd512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n",
      "\n",
      "Guess: 1\n",
      "['g', 'l', 'e', 'e', 's']\n",
      "\tS (Y)\t\tA (R)\t\tN (R)\t\tE (G)\t\tS (G)\t\n",
      "Guess: 2\n",
      "['g', 'l', 'e', 'e', 's']\n",
      "\tP (R)\t\tO (R)\t\tL (Y)\t\tE (G)\t\tS (G)\t\n",
      "Guess: 3\n",
      "['g', 'l', 'e', 'e', 's']\n",
      "\tL (Y)\t\tU (R)\t\tG (Y)\t\tE (G)\t\tS (G)\t\n",
      "Guess: 4\n",
      "['g', 'l', 'e', 'e', 's']\n",
      "\tG (G)\t\tL (G)\t\tE (G)\t\tE (G)\t\tS (G)\t\n",
      "\n",
      "Congrats! You got the correct word\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "DF_GUESS = pd.DataFrame()\n",
    "\n",
    "def load_words(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        words = f.read().splitlines()\n",
    "        words = [w for w in words if len(w) == 5]\n",
    "    return words\n",
    "\n",
    "def calculate_weights():\n",
    "    \n",
    "    global DF_GUESS\n",
    "    for i in range(1,6):\n",
    "        DF_GUESS['letter_'+ str(i) +'_freq'] = DF_GUESS['letter_'+ str(i)].map(DF_GUESS['letter_'+ str(i)].value_counts())\n",
    "    \n",
    "    DF_GUESS['CumiWeight'] = DF_GUESS['letter_1_freq']+ DF_GUESS['letter_2_freq'] + DF_GUESS['letter_3_freq'] + DF_GUESS['letter_4_freq'] + DF_GUESS['letter_5_freq']\n",
    "    DF_GUESS = DF_GUESS.sort_values('CumiWeight', ignore_index=True,  ascending=False)\n",
    "    #print(DF_GUESS.head())\n",
    "\n",
    "\n",
    "def initialize_agent(wordle_list):\n",
    "\n",
    "    global DF_GUESS\n",
    "    DF_GUESS = pd.DataFrame(wordle_list, columns =['words'], dtype = str)\n",
    "    DF_GUESS['letters'] = DF_GUESS['words'].apply(list)\n",
    "\n",
    "    # Apply the function to each row and create new columns for each letter\n",
    "    for index, row in DF_GUESS.iterrows():\n",
    "        word = row['words']\n",
    "        letters = list(word)\n",
    "        for i, letter in enumerate(letters):\n",
    "            DF_GUESS.at[index, 'letter_' + str(i+1)] = letter\n",
    "    \n",
    "    calculate_weights()\n",
    "\n",
    "def guess_feedback(feedback, previousGuess):\n",
    "    \n",
    "    global DF_GUESS\n",
    "    count = 0\n",
    "    for i in feedback:\n",
    "        focus_letter = previousGuess[count]\n",
    "        if i == 'G':\n",
    "            DF_GUESS = DF_GUESS.loc[DF_GUESS['letter_' + str(count+1)] == focus_letter]\n",
    "        if i == 'Y':\n",
    "            yList = [x for x in DF_GUESS.index if focus_letter in DF_GUESS[\"words\"][x]]\n",
    "            DF_GUESS = DF_GUESS.loc[yList]\n",
    "            DF_GUESS = DF_GUESS.loc[DF_GUESS['letter_' + str(count+1)] != focus_letter]\n",
    "        if i == 'R':\n",
    "            dropList = [x for x in DF_GUESS.index if focus_letter in DF_GUESS[\"words\"][x]]\n",
    "            DF_GUESS = DF_GUESS.drop(dropList, axis=0)\n",
    "        count += 1\n",
    "    \n",
    "    calculate_weights()\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    global DF_GUESS\n",
    "    words = load_words(\"words_alpha.txt\")\n",
    "    \n",
    "\n",
    "    print(\"Initializing...\")\n",
    "    initialize_agent(words)\n",
    "\n",
    "    wordle_word_to_guess = random.choice(words)\n",
    "\n",
    "    for attempt in range(6):\n",
    "    \n",
    "        if attempt == 5:\n",
    "            print(\"\\n\\nYour last attempt\")\n",
    "\n",
    "        print(\"\\nGuess: \" + str(attempt+1))\n",
    "        guess_input = DF_GUESS[\"words\"][0]\n",
    "        while True: \n",
    "    \n",
    "            if len(guess_input) == 5 and re.match(\"^[a-zA-Z]*$\", guess_input):\n",
    "                    break\n",
    "            else:\n",
    "                if not re.match(\"^[a-zA-Z]*$\", guess_input):\n",
    "                    print(\"\\nError! Only letters a-z or A-Z allowed!\")\n",
    "                elif len(guess_input) < 5:\n",
    "                    print(\"\\nError! There are only\" , len(guess_input) , \"words. Kindly input 5 letters only.\" )\n",
    "                elif len(guess_input) > 5:\n",
    "                    print(\"\\nError! There are\" , len(guess_input) ,\"words, which is more than 5. Kindly input 5 letters only.\" )\n",
    "                guess_input = input(\"\\nPlease make your guess: \")\n",
    "        \n",
    "        \n",
    "        # print(list(guess_input))\n",
    "        print(list(wordle_word_to_guess))\n",
    "\n",
    "        guess_input_letters = list(guess_input)\n",
    "        wordle_word_to_guess_letters = list(wordle_word_to_guess)\n",
    "\n",
    "\n",
    "        feedback_list = []\n",
    "        result = []\n",
    "\n",
    "        #guess_input_letters = ['l', 'a', 'l', 'a', 'l']\n",
    "        #wordle_word_to_guess_letters = ['c', 'a', 't', 'c', 'h']\n",
    "\n",
    "        for i in range(len(guess_input_letters)):\n",
    "            if guess_input_letters[i] == wordle_word_to_guess_letters[i]:\n",
    "                feedback_list.append(\"G\")\n",
    "                result.append(guess_input_letters[i]+ \" (G)\")\n",
    "            elif guess_input_letters[i] in wordle_word_to_guess_letters:\n",
    "                feedback_list.append(\"Y\")\n",
    "                result.append(guess_input_letters[i]+ \" (Y)\")\n",
    "            else:\n",
    "                feedback_list.append(\"R\")\n",
    "                result.append(guess_input_letters[i]+ \" (R)\")\n",
    "        \n",
    "        for letter in result:\n",
    "            print(\"\\t\"+letter.upper()+\"\\t\", end=\"\")\n",
    "        \n",
    "        guess_feedback(feedback_list, guess_input_letters)\n",
    "        \n",
    "        if guess_input_letters == wordle_word_to_guess_letters:\n",
    "            print(\"\\n\\nCongrats! You got the correct word\")\n",
    "            break\n",
    "        elif attempt == 5:\n",
    "            print(\"\\n\\nEnd of Game! Boo!\")\n",
    "            break\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1fc79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a9d5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e11f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef8ddfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0276d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90fe4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b429a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd9bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38d3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb152a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738f6591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66d771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b66327d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216dfcbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a532b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeafc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c389c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3640780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42388fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4dc2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38010164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c8f439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6032c78e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc83a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa146dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b980c51f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "wordle word to guess: fluer\n",
      "\n",
      "Guess: 1\n",
      "  S  A  N  E  S\n",
      "Guess: 2\n",
      "  C  O  R  E  R\n",
      "Guess: 3\n",
      "  F  I  V  E  R\n",
      "Guess: 4\n",
      "  F  L  Y  E  R\n",
      "Guess: 5\n",
      "  F  L  E  E  R\n",
      "Guess: 6\n",
      "  F  L  U  E  R\n",
      "\n",
      "Congrats! You got the correct word : fluer\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "\n",
    "\n",
    "# Creating a global dataframe to contain all the words and their probabilistic weights\n",
    "# for each position of the letter. Making it a global variable for easy access across \n",
    "# all functions to edit the dataframe after each guess.\n",
    "DF_GUESS = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Loads the words dataset and filters all the words whose lenght is not 5.\n",
    "def load_words(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        words = f.read().splitlines()\n",
    "        words = [w for w in words if len(w) == 5]\n",
    "    return words\n",
    "\n",
    "\n",
    "\n",
    "# Calculates the frequency of each letter in each position and sums it up for each word in the dataframe.\n",
    "def calculate_weights():\n",
    "    # To access the global variable DF_GUESS\n",
    "    global DF_GUESS\n",
    "\n",
    "    # Calculating the frequency of each letter in each position.\n",
    "    for i in range(1,6):\n",
    "       DF_GUESS['letter_'+ str(i) +'_freq'] = DF_GUESS['letter_'+ str(i)].map(DF_GUESS['letter_'+ str(i)].value_counts())\n",
    "    \n",
    "    # Adding all the frequencies of each letter for every word and storing it in the CumiWeight column of the dataframe.\n",
    "    DF_GUESS['CumiWeight'] = DF_GUESS['letter_1_freq']+DF_GUESS['letter_2_freq'] +DF_GUESS['letter_3_freq'] +DF_GUESS['letter_4_freq'] +DF_GUESS['letter_5_freq']\n",
    "    \n",
    "    # Sorting the dataframe with the highest total frequency at the top.\n",
    "    # This is so that the word which has the highest total frequncy for each letter in each position is our first guess.\n",
    "    DF_GUESS = DF_GUESS.sort_values('CumiWeight', ignore_index=True,  ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "# Initialises the dataframe on the first run with the words of the dataset, their frequncies and cumulative weights.\n",
    "def initialize_dataframe(wordle_list):\n",
    "    global DF_GUESS\n",
    "\n",
    "    DF_GUESS = pd.DataFrame(wordle_list, columns =['words'], dtype = str)\n",
    "    DF_GUESS['letters'] = DF_GUESS['words'].apply(list)\n",
    "\n",
    "    # Creating new columns for each position of the letter, this is required to calculate the frequency\n",
    "    # of each letter and the cumulilative weight of the entire word.\n",
    "    for index, row in DF_GUESS.iterrows():\n",
    "        word = row['words']\n",
    "        letters = list(word)\n",
    "        for i, letter in enumerate(letters):\n",
    "            DF_GUESS.at[index, 'letter_' + str(i+1)] = letter\n",
    "    \n",
    "    # Calculating the weights for the initial set of words.\n",
    "    calculate_weights()\n",
    "\n",
    "\n",
    "# Updates the DF_GUESS dataframe with the feedback recieved from previous guesses.\n",
    "def guess_word(feedback, previousGuess, gs_ys):\n",
    "\n",
    "    global DF_GUESS\n",
    "\n",
    "    # count is the current position as we iterate through the feedback.\n",
    "    count = 0\n",
    "\n",
    "    for i in feedback:\n",
    "\n",
    "        # We are iterating through the feedback received for each letter of the previous guess,\n",
    "        # focus_letter denotes that letter.\n",
    "        focus_letter = previousGuess[count]\n",
    "\n",
    "        # If the focus_letter color is green, the dataframe is updated with all the words having the focus_letter\n",
    "        # in the current position of the iteration.\n",
    "        if i == 'G':\n",
    "            DF_GUESS = DF_GUESS.loc[DF_GUESS['letter_' + str(count+1)] == focus_letter]\n",
    "\n",
    "        # If the focus_letter color is yellow, the dataframe is updated with all the words containing the focus_letter,\n",
    "        # and all the words containing the focus letter in the current position are removed from the dataframe.\n",
    "        if i == 'Y':\n",
    "            yList = [x for x in DF_GUESS.index if focus_letter in DF_GUESS[\"words\"][x]]\n",
    "            DF_GUESS = DF_GUESS.loc[yList]\n",
    "            DF_GUESS = DF_GUESS.loc[DF_GUESS['letter_' + str(count+1)] != focus_letter]\n",
    "\n",
    "        # If the focus_letter color is red and the letter is also marked green or yellow, all the words containing the\n",
    "        # focus_letter only in the current position are deleted. Otherwise, if focus_letter is red and is not marked \n",
    "        # green or yellow, all the words containing the focus_letter are deleted.\n",
    "        if (i == 'R') and (focus_letter in gs_ys):\n",
    "            DF_GUESS = DF_GUESS.loc[DF_GUESS['letter_' + str(count+1)] != focus_letter]\n",
    "        elif i == 'R':\n",
    "            dropList = [x for x in DF_GUESS.index if focus_letter in DF_GUESS[\"words\"][x]]\n",
    "            DF_GUESS = DF_GUESS.drop(dropList, axis=0)\n",
    "        \n",
    "        count += 1\n",
    "\n",
    "    # Weights are again calculated for the newly updated dataframe which is based on the previous guess.\n",
    "    calculate_weights()\n",
    "    \n",
    "\n",
    "def main():\n",
    "    \n",
    "    global DF_GUESS\n",
    "    words = load_words(\"words_alpha.txt\")\n",
    "\n",
    "    initialize_dataframe(words)\n",
    "\n",
    "    wordle_word_to_guess = random.choice(words)\n",
    "\n",
    "    print(\"\\nwordle word to guess: \" + wordle_word_to_guess)\n",
    "\n",
    "    for attempt in range(6):\n",
    "\n",
    "        print(\"\\nGuess: \" + str(attempt+1))\n",
    "\n",
    "        # Our first guess is the word with the highest cumulative weight, which is the first word of the\n",
    "        # sorted dataframe.\n",
    "        guess_input = DF_GUESS[\"words\"][0]\n",
    "\n",
    "        guess_input_letters = list(guess_input)\n",
    "        wordle_word_to_guess_letters = list(wordle_word_to_guess)\n",
    "\n",
    "        # Creating a copy of the word to be guessed to make sure we mark the correct color to the correct letter.\n",
    "        pop_list = wordle_word_to_guess_letters.copy()\n",
    "\n",
    "        # A list to contain the feedback of the word\n",
    "        feedback_list = []\n",
    "\n",
    "        # A list to append the colored version of the output on the terminal.\n",
    "        result = []\n",
    "\n",
    "        # gs is a list for all the letters to be marked green.\n",
    "        gs = []\n",
    "\n",
    "        # gs_ys is a list of all the letters which are marked green and yellow.\n",
    "        gs_ys = []\n",
    "\n",
    "        # We are iterating through the guessed letter and marking \n",
    "        # - G for green indicating the letter is in the right position\n",
    "        # - Y for yelllow indicating the letter is in the word but in the wrong position.\n",
    "        # - R for red indicating the letter is not in the word.\n",
    "        for i in range(len(guess_input_letters)):\n",
    "            if guess_input_letters[i] == wordle_word_to_guess_letters[i]:\n",
    "                feedback_list.append(\"G\")\n",
    "                gs.append(i)\n",
    "                gs_ys.append(guess_input_letters[i])\n",
    "                result.append(colored(guess_input_letters[i].upper(), 'green'))\n",
    "            elif guess_input_letters[i] in pop_list:\n",
    "                feedback_list.append(\"Y\")\n",
    "                gs_ys.append(guess_input_letters[i])\n",
    "                result.append(colored(guess_input_letters[i].upper(), 'yellow'))\n",
    "            else:\n",
    "                feedback_list.append(\"R\")\n",
    "                result.append(colored(guess_input_letters[i].upper(), 'red'))\n",
    "\n",
    "        # Removing all the letters which are marked green from the pop_list.\n",
    "        pop_list = [l for i, l in enumerate(pop_list) if i not in gs]\n",
    "        \n",
    "        # Iterating through the feedback_list and checking for all values of Y if they are in pop_list or not.\n",
    "        # If they are in the pop_list, we are removing them from the list, else the specific letter is marked red.\n",
    "        # This is so that no two same letters are marked Y if only one of them exists in the word to be guessed.\n",
    "        for indx, lettr in enumerate(feedback_list):\n",
    "            if (lettr == \"Y\") and (guess_input_letters[indx] in pop_list):\n",
    "                pop_list.remove(guess_input_letters[indx])\n",
    "            elif lettr == \"Y\":\n",
    "                feedback_list[indx] = \"R\"\n",
    "                result[indx] = colored(guess_input_letters[indx].upper(), 'red')\n",
    "        \n",
    "        \n",
    "        for letter in result:\n",
    "            print(\"  \" + letter, end=\"\")\n",
    "                \n",
    "        guess_word(feedback_list, guess_input_letters, gs_ys)\n",
    "        \n",
    "        if guess_input_letters == wordle_word_to_guess_letters:\n",
    "            print(\"\\n\\nCongrats! You got the correct word : \"  + wordle_word_to_guess)\n",
    "            break\n",
    "        elif attempt == 5:\n",
    "            print(\"\\n\\nEnd of Game! Boo!\")\n",
    "            print(\"\\nThe correct word is: \" + wordle_word_to_guess)\n",
    "            break\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11893a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f12146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1df767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d585443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca9e5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
